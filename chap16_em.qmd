# 利益マネジメント

<!-- A significant body of accounting research focuses on earnings management.  -->
利益マネジメントに焦点を当てた会計研究が数多く存在する。
<!-- One definition of earnings management might be "intervention by managers in the accounting process with a view to achieving
financial reporting outcomes that benefit managers." -->
利益マネジメントの定義の1つは、「経営者にベネフィットをもたらす財務報告結果を達成することを目的とした，経営者による会計プロセスへの介入」というものである。

<!-- A classic form of earnings management is channel stuffing, which is a way for a company to report higher sales (and perhaps higher profits) in a period by pushing more products through a distribution channel than is needed to meet underlying demand.  -->
古典的な利益マネジメントの形態の1つに**チャネル・スタッフィング**(channel stuffing)がある。
これは、実際の需要を超える製品を流通チャネルを押し込むことで、企業がある期間の売上高（場合によっては利益）をより高く見せる手法である。
<!-- A classic case of channel stuffing involved the Contact Lens Division ("CLD") of Bausch and Lomb ("B&L"). -->
チャネル・スタッフィングの古典的な事例として、ボシュロム（B&L）のコンタクトレンズ部門（CLD）が関与したものがある。
<!-- According to the SEC, "B&L materially overstated its net income for 1993 by improperly recognizing revenue from the sale of contact lenses.  -->
米国証券取引委員会(SEC)によると、「ボシュロムはコンタクトレンズの売上高を不適切に認識することにより、1993年の純利益を実質的に過大に報告した。
<!-- These overstatements of revenue ... arose from sales of significant amounts of contact lenses to the CLD's distributors less than two weeks before B&L's 1993 fiscal year-end in connection with a marketing program that effectively resulted in consignment sales."  -->
これらの売上高の過大報告は、ボシュロムの1993年度末までの2週間以内にCLDの販売代理店に大量のコンタクトレンズを販売し、事実上委託販売となったマーケティングプログラムに関連して発生した。
<!-- In the case, the sales were not appropriately recognized as revenue during fiscal 1993 because "certain employees of the CLD granted unauthorized rights of return to certain distributors and shipped contact lenses after the fiscal year-end." -->
この事例では，「コンタクトレンズ部門の従業員が特定の代理店に対して無許可の返品権を与え、期末後にコンタクトレンズを出荷した」ため、1993年の売上高が適切に認識されなかった。

<!-- While B&L's channel stuffing was clearly earnings management (and in violation of generally accepted accounting principles, or GAAP), firms may engage in less extreme practices that are motivated by a desire to deliver higher sales in the current period, but do not involve any violation of GAAP or direct manipulation of the accounting process, yet would be generally regarded as earnings management.  -->
ボシュロムのチャネル・スタッフィングは明らかに利益マネジメントであり（一般に公正妥当と認められる会計原則, GAAPに違反している）、企業は当期により高い売上高を達成したいという動機から、より極端でない会計慣行に従事する場合がある。これらはGAAPや会計処理の直接的な操作には違反しないものの，一般的には利益マネジメントと見なされるだろう。
<!-- In such cases, earnings management is achieved by so-called real activities (i.e., those affecting business realities such as when products are delivered) and this form of earnings management is called real earnings management. -->
このような場合、利益マネジメントは、いわゆる実際の活動（つまり、製品が配送されるときなどのビジネスの現実に影響を与えるもの）によって達成され、この形態の利益マネジメントは**実体的利益マネジメント**(real earnings management)と呼ばれる。
<!-- Thus, not all forms of earnings management involve direct manipulation of the accounting process. -->
したがって、利益マネジメントのすべての形態が会計プロセスの直接的な操作を含むわけではない。

<!-- But once we allow for real earnings management, it can be difficult to distinguish, even in principle, actions taken to increase firm value that happen to benefit managers because of their financial reporting effects from actions that might fit more conventional notions of earnings management. -->
しかし、実体的利益マネジメントを許容すると、原則として、会社価値を高めるために行われた行動と、財務報告の影響によって経営者に利益をもたらす行動を区別することは困難になるかもしれない。

<!-- Another difficulty discussed by Beaver (1998) is the existence of alternative views of earnings management. -->
Beaver (1998)が議論したもう1つの困難は、利益マネジメントの代替的な見方が存在することである。
<!-- While actions by managers to “manipulate the financial reporting system in ways that enhance management’s well-being to the [detriment] of capital suppliers and others” (Beaver, 1998, p. 84) clearly meet the definition above, it is possible that earnings management allows managers “to reveal … private information to investors.” -->
「経営者が資本提供者やその他の人々にとって不利益となる方法で財務報告システムを操作する」(Beaver、1998年, p.84)という定義を満たす行動は明らかであるが、利益マネジメントによって経営者が「投資家に向けて…私的情報(private information)を明らかにする」ことが可能である。


<!-- We also note that Beaver (1998, p. 83) views earnings management as just one form a wide class of "discretionary behaviour", which also includes voluntary disclosures, such as earnings forecasts. -->
また本書では、Beaver (1998, p.83)が利益マネジメントを利益予測などの自発的開示を含む広範な「裁量的行動」の1つの形態と見なしていることにも注意する。


:::{.callout-tip}
<!-- The code in this chapter uses the packages listed below. -->
本章のコードは以下のパッケージを使用する。
<!-- Rather than invoking several Tidyverse packages separately, we load the tidyverse package.  -->
tidyverseパッケージを個別に呼び出す代わりに、tidyverseパッケージを読み込む。
<!-- For instructions on how to set up your computer to use the code found in this book, see Section 1.2. -->
この本のコードを使用するためのコンピュータの設定方法については、1.2節を参照せよ。
<!-- Quarto templates for the exercises below are available on GitHub. -->
以下の演習問題のQuartoテンプレートはGitHubで入手できる。
:::

```{r}
pacman::p_load(tidyverse, DBI, farr, broom, furrr)
```

## 利益マネジメントを測定する

<!-- Even putting aside definitional issues, a challenge for researchers seeking to understand earnings management - the prevalence of the mechanisms through which it is achieved, and the effects that it has - is detecting and measuring it.  -->
定義上の問題を置いておいても、利益マネジメントを理解しようとする研究者にとっての課題は、それを検出し、測定することである。
<!-- In this section, we use discussion questions to explore two early papers (Jones, 1991; McNichols and Wilson, 1988) that illustrate some key issues and approaches that researchers have used to address these. -->
この節では、2つの初期の論文（Jones, 1991; McNichols and Wilson, 1988）を用いて、研究者がこれらの問題に取り組むために使用してきたいくつかの主要な問題やアプローチを探るために、ディスカッション問題を用いる。

### Discussion questions

<!-- 1. Jones (1991) focuses on a small number of firms. Why does Jones (1991) have such a small sample? What are the disadvantages of a small sample? Are there advantages of a smaller sample or narrower focus? -->
1. Jones (1991)は少数の企業に焦点を当てている。なぜJones (1991)はそのように小さなサンプルを持っているのか？小さなサンプルの欠点は何か？小さなサンプルや狭い焦点の利点はあるか？

<!-- 2. What are the primary conclusions of Jones (1991)?  -->
2. Jones (1991)の主な結論は何か？
<!-- Which table presents the main results of Jones (1991)?  -->
Jones (1991)の主な結果を示しているのはどの表か？
<!-- Describe the empirical test used in that table. Can you suggest an alternative approach?  -->
その表で使用されている実証テストを説明してください。代替手法を提案できますか？
<!-- What do you see as the primary challenges to the conclusions of Jones (1991)? -->
Jones (1991)の結論に対する主な課題は何だと思いますか？

<!-- 3. Can you think of refinements to the broad research question? What tests might you use to examine these? -->
3. 広範な研究問題についてどのような改良案が思い浮かびますか？これらを検討するためにどのようなテストを使用するか？

<!-- 4. McNichols and Wilson (1988) state at the outset that their paper “examines whether managers manipulate earnings.”  -->
4. McNichols and Wilson (1988)は、論文の冒頭で「経営者が利益を操作しているかどうかを検証する」と述べています。
<!-- Is this a good statement of the main research question of McNichols and Wilson (1988)?  -->
これは、McNichols and Wilson (1988)の主要な研究課題をよく表しているか？
<!-- If not, suggest an alternative summary of the research questions of McNichols and Wilson (1988). -->
そうでない場合、McNichols and Wilson (1988)の研究問題の代替の要約を提案しなさい。

<!-- 5. What do McNichols and Wilson (1988) mean by "nondiscretionary accruals?" -->
5. McNichols and Wilson (1988)のいう「非裁量的アクルーアル」とは何を意味しているのか？
<!-- How "operationalizable" is this concept?[^1] -->
この概念はどれだけ「操作可能」か？[^1]

[^1]: See [(https://en.wiktionary.org/wiki/operationalizable#English)](https://en.wiktionary.org/wiki/operationalizable#English)

<!-- 6. McNichols and Wilson (1988) say “if were observable, accrual-based tests of earnings management would be expressed in terms of the following regression: -->
6. McNichols and Wilson (1988)は、「観測可能であれば、利益マネジメントのアクルーアルに基づくテストは、次の回帰式で表される」と述べている。

$$
DA = \alpha + \beta PART + \varepsilon
$$

<!-- where $PART$ is a dummy variable that partitions the data into two groups for which earnings management predictions are specified”.  -->
ここで、　$PART$　はデータを2つのグループに分割し、利益マネジメントの予測が指定されたダミー変数である」と述べている。
<!-- Healy (1985) points out that bonus plans can give managers incentives to increase earnings or decrease earnings depending on the situation.  -->
Healy (1985)は、ボーナス制度が、状況に応じて経営者に利益を増やすか減らすかのインセンティブを与えることを指摘している。
<!-- How is this problematic for the formulation of McNichols and Wilson (1988) above?  -->
これは、上記のMcNichols and Wilson (1988)の定式化にとって問題となるのはなぜか？
<!-- How might a researcher address this? -->
研究者はどのように対処すべきだろうか？

<!-- 7. What are the benefits and costs of focusing on a single item (bad debt expense) in a study of earnings management? -->
7. 利益マネジメントの研究で1つの項目（貸倒引当金）に焦点を当てる利点と欠点は何か？

<!-- 8. The main results of McNichols and Wilson (1988) are in Tables 6 and 7.  -->
8. McNichols and Wilson (1988)の主な結果は、表6と表7にある。
<!-- How persuasive do you find the evidence of earnings management found in the “residual provision” columns of those tables? -->
これらの表の「残存規定」列に見られる利益マネジメントの証拠はどれほど説得力があるのか？

<!-- 9. How well does the framework apply to Jones (1991)? Does the framework require modification for this paper? In which periods would be set to one in Jones (1991)? -->
9. このフレームワークはJones (1991)に適用されていますか？この論文にはフレームワークの修正が必要か？
Jones (1991)ではどの期間が1に設定されるのか？

<!-- ## Evaluating measures of earnings management -->
## 利益マネジメント尺度の評価

<!-- A natural question that arises is how well measures of earnings management such as that used in Jones (1991) perform. -->
自然な疑問として、Jones (1991)で使用されているような利益マネジメントの尺度がどれほどうまく機能するかということが挙げられる。
<!-- An ideal measure would detect earnings management when it is present, but not detect earnings management when it is absent. -->
理想的な尺度は、利益マネジメントが存在するときにはそれを検出し、利益マネジメントが存在しないときにはそれを検出しない。
<!-- This leads to two questions. -->
これにより、2つの疑問が生じる。
<!-- First, how well does a given measure detect earnings management when it is present? -->
第1に、利益マネジメントが存在するときに、どのようにして特定の尺度が利益マネジメントを検出するか？
<!-- Second, how does a given measure behave when earnings management is not present? -->
第2に、利益マネジメントが存在しないときに、特定の尺度がどのように振る舞うか？

<!-- Dechow et al. (1995) evaluate five earnings management measures from prior research on these terms. -->
Dechow et al. (1995) は、これらの条件に基づいて、先行研究からの5つの利益マネジメント尺度を評価している。
<!-- Each of these measures uses an estimation period to create a model of non-discretionary accruals which is then applied to measure discretionary accruals for a test period as the difference between total accruals and estimated non-discretionary accruals. -->
これらの尺度のそれぞれは、推定期間を使用して非裁量的アクルーアルのモデルを作成し、その後、推定された非裁量的アクルーアルとの差として、テスト期間の裁量的アクルーアルを測定する。
<!-- Assuming that the estimation period runs from $t=1$ to $t = T$, these measures are defined, for firm $i$ in year $\tau$, as follows: -->
推定期間が$t=1$から$t=T$までであると仮定すると、これらの尺度は、企業$i$の年度$\tau$について以下のように定義される。

<!-- - The Healy Model (Healy, 1985) measures non-discretionary accruals as mean total accruals during the estimation period -->
- Healyモデル（Healy、1985）は、推定期間中の平均総アクルーアルを非裁量的アクルーアルとして測定する。

$$
NDA_{i, tau} = \frac{\sum _{t=1}^{T} TA_{i,t}}{T}
$$

<!-- where $TA_{i,t}$ is (both here and below) total accruals scaled by lagged total assets. -->
ここで、$TA_{i,t}$は（以下も同様）遅延総資産でスケーリングされた総アクルーアルである。


<!-- The DeAngelo Model (DeAngelo, 1986) uses last period’s total accruals as the measure of nondiscretionary accruals. -->
- DeAngeloモデル（DeAngelo、1986）は、前期の総アクルーアルを非裁量的アクルーアルの尺度として使用する。

$$
NDA_{i, tau} = TA_{i,t}
$$

<!-- The Jones Model (Jones, 1991) “attempts to control for the effect of changes in a firm’s economic circumstances on nondiscretionary accruals” using the following model: -->
- Jonesモデル（Jones、1991）は、「企業の経済状況の変化が非裁量的アクルーアルに与える影響を制御しようとする」次のモデルを使用する。

$$
NDA_{i, tau} = \alpha_1 (1/AT_{i, \tau -1} ) + \alpha_2 \Delta REV_{i,\tau} + \alpha_3 PPE_{i, \tau}
$$

ここで $AT_{i, \tau -1}$ は企業 $i$ の $\tau -1$ 時点の総資産、$\Delta REV _{i, \tau}$ は $\tau$ 年度の売上高から $\tau - 1$ 年度の売上を引いたものを $AT_{i, \tau - 1}$ で基準化したもの、 $PPE _{i, \tau}$ は $i$ 企業の $\tau$ 年度における有形固定資産を $AT_{i, \tau-1}$ で基準化したものである。

<!-- - **Modified Jones Model**. Dechow et al. (1995) consider a modified version of the Jones Model "designed to eliminate the conjectured tendency of the Jones Model to measure discretionary accruals with error when discretion is exercised over revenues" (1995, p. 199).  -->
- **修正Jonesモデル** : Dechow et al. (1995)は、Jonesモデルの修正バージョンを考慮しており、「Jonesモデルが収益に対して裁量を行うときに裁量的アクルーアルを誤って測定するという推測される傾向を排除するために設計された」 (1995, p.199)。
<!-- In this model, non-discretionary accruals are estimated during the event period as:  -->
このモデルでは、イベント期間中の非裁量的アクルーアルは次のように推定される。

$$
NDA_{i, \tau} = \alpha_1 (1/AT_{i, \tau -1} ) +
    \alpha_2 ( \Delta REV_{i,\tau} - \Delta REC_{i,\tau} ) +
    \alpha_3 PPE_{i, \tau}
$$

ここで $\Delta REC_{i,\tau}$ は、企業 $i$ の $\tau$ 年度の売掛金から $\tau - 1$ 年度の売掛金を引いたものを $AT_{i, \tau - 1}$ で基準化したものである。

<!-- - **The Industry Model** "relaxes the assumption that non-discretionary accruals are constant over time. The Industry Model assumes that variation in the determinants of non-discretionary accruals are common across firms in the same industry" (1995, p. 199).  -->
- **産業モデル** : 「非裁量的アクルーアルが時間とともに一定であるという仮定を緩和する。産業モデルは、非裁量的アクルーアルの決定要因の変動が、同じ業界の企業間で共通であると仮定している」 (1995)、p.199）。
<!-- In this model, non-discretionary accruals are calculated as: -->
このモデルでは、非裁量的アクルーアルは次のように計算される。

$$
NDA_{i, \tau} = \gamma _1 + \gamma _2 \text{median} (TA_{I, \tau)})
$$

ここで $TA_{I,\tau}$ は産業 $I \ (\forall j \in I)$ における全企業の $TA_{j, \tau }$ の値である。

<!-- In each of the models above, the parameters (i.e., $(\alpha _1, \alpha _2, \alpha _3$) or ($\gamma _1, \gamma _2$) are estimated on a firm-specific basis during the estimation period. -->
上記の各モデルでは、パラメータ（すなわち、$(\alpha _1, \alpha _2, \alpha _3$)または($\gamma _1, \gamma _2$)）は、推定期間中に企業ごとに推定される。


<!-- Dechow et al. (1995) conduct analyses on four distinct samples, with each designed to test a different question.  -->
Dechow et al. (1995) は、異なる質問をテストするために設計された4つの異なるサンプルで分析を行う。
<!-- Drawing on the framework from McNichols and Wilson (1988), an indicator variable $PART$ is set to one for a subset of firm-years in each sample: -->
McNichols and Wilson (1988)のフレームワークを活用し、各サンプルの一部の企業年度に対して指標変数$PART$を1に設定する。

<!-- 1. Randomly selected samples of 1000 firm-years. -->
1. 1000企業年度のランダムに選択されたサンプル
<!-- 2. Samples of 1000 firm-years randomly selected from firm-years experiencing extreme financial performance. -->
2. 極端な財務業績を経験している企業年度からランダムに選択された1000企業年度のサンプル
<!-- 3. Samples of 1000 firm-years randomly selected to which a fixed and known amount of accrual manipulation is introduced. -->
3. 1000企業年度のサンプルで、固定された既知のアクルーアル操作が導入される
<!-- 4. Samples based on SEC enforcement actions. -->
4. SECの執行措置に基づくサンプル

<!-- Here we conduct a replication of sorts of Dechow et al. (1995). -->
ここでは、Dechow et al. (1995) のある種の複製を行う。
<!-- We consider the first three samples, but omit the fourth sample. -->
最初の3つのサンプルを考慮するが、4番目のサンプルは省略する。
Data for our analysis come from two tables on Compustat: comp.funda and comp.company.2
本稿の分析のためのデータは、Compustatの2つのテーブル、`comp.funda`と`comp.company`から取得される。[^2]

[^2]: As in Chapter 15, we supplement data on `comp.funda` with SIC codes from `comp.company`.


```{r}
#| eval: false
db <- dbConnect(RPostgres::Postgres(), bigint = "integer")

funda <- tbl(db, Id(schema = "comp", table = "funda"))
company <- tbl(db, Id(schema = "comp", table = "company"))
```

<!-- For financial statement data, we construct funda_mod in exactly the same way as we did in Chapter 15. -->
財務諸表データについては、第15章と同様に`funda_mod`を構築する。


```{r}
#| eval: false
sics <-
  company |>
  select(gvkey, sic) |>
  mutate(sic = as.integer(sic))

funda_mod <-
  funda |>
  filter(indfmt == "INDL", datafmt == "STD",
         consol == "C", popsrc == "D") |>
  left_join(sics, by = "gvkey") |>
  mutate(sic = coalesce(sich, sic))
```

<!-- Sloan (1996, p. 293) suggests that the data needed to calculate accruals are not available for “banks, life insurance or property and casualty companies”, so we exclude these firms (those with SIC codes starting with 6).  -->
Sloan (1996, p.293) は、「銀行、生命保険、損害保険会社」のデータを計算するためのデータが利用できないと述べているため、これらの企業（SICコードが6で始まる企業）を除外する。
<!-- Following Dechow et al. (1995), we restrict the sample to the years 1950–1991.-->
Dechow et al. (1995) に従い、サンプルを1950年から1991年までの年に制限する。[^3]
<!-- We also limit our sample to firm-years with non-missing assets and with twelve months in the fiscal period (pddur == 12). -->
また、資産が欠損していない企業年度と、会計期間が12か月の企業年度に制限する(`pddur == 12`)。

[^3]: Because we need lagged values for most analyses, in only collecting data from 1950, we will lose that first year from most analyses. It is unclear whether Dechow et al. (1995) collected data for 1949 to be able to use 1950 firm-years in their analysis, but it is unlikely to have much of an impact (there are few firms in the data for 1950) and it would be easy to tweak if we wanted to include 1950 in our analysis.


```{r}
#| eval: false

acc_data_raw <-
  funda_mod |>
  filter(!is.na(at), # ATの欠損値を除外
         pddur == 12, # 会計期間が12か月の企業年度
         !between(sic, 6000, 6999)) |> # SICコードが6で始まる企業を除外
  mutate( # che, dlc, sale, rectの欠損値を0で埋める
    across(c(che, dlc, sale, rect), \(x) coalesce(x, 0))
  ) |>
  select(gvkey, datadate, fyear, at, ib, dp, rect,
    ppegt, ni, sale, act, che, lct, dlc, sic) |> # 変数を選択
  filter(between(fyear, 1950, 1991)) |> # 1950年から1991年までの年に制限
  arrange(gvkey, fyear) |> # gvkeyとfyearで並び替え
  collect() # データを収集
```

<!-- Like Sloan (1996) and Jones (1991), Dechow et al. (1995) measure accruals using a balance-sheet approach.  -->
Sloan (1996)やJones (1991)と同様に、Dechow et al. (1995) は、貸借対照表アプローチを使用してアクルーアルを測定する。
<!-- The following function takes a data frame with the necessary Compustat variables, and calculates accruals for each firm-year, returning the resulting data set. -->
次の関数は、必要なCompustat変数を持つデータフレームを取り、各企業年度の総アクルーアルを計算し、結果のデータセットを返す。

```{r}
calc_accruals <- function(df) {
  df |>
    group_by(gvkey) |> # gvkeyでグループ化
    arrange(datadate) |> # datadateで並び替え
    mutate(lag_at = lag(at),
           d_ca = act - lag(act), # 流動資産変化
           d_cash = che - lag(che), # 現金変化額
           d_cl = lct - lag(lct), # 流動負債変化
           d_std = dlc - lag(dlc), # 短期借入金変化
           d_rev = sale - lag(sale), # 売上高変化
           d_rec = rect - lag(rect)) |> # る売掛金変化
    ungroup() |> # グループ化を解除
    mutate(　# 総アクルーアルを計算
      acc_raw =  (d_ca - d_cash - d_cl + d_std) - dp
      )
}
```

<!-- Like Jones (1991), Dechow et al. (1995) split firm-level data into an estimation period and a test firm-year and estimate earnings management models on a firm-specific basis.  -->
Jones (1991)と同様に、Dechow et al. (1995) は、企業レベルのデータを推定期間とテスト企業年度に分割し、企業ごとに利益マネジメントモデルを推定する。
<!-- Dechow et al. (1995) require at least 10 years in the estimation period and each sample firm will have one test firm-year by construction.  -->
Dechow et al. (1995) は、推定期間に少なくとも10年が必要であり、各サンプル企業は構築により1つのテスト企業年度を持つ。
<!-- To give effect to this, we construct a sample of candidate firm-years comprising firms with at least 11 years with required data. -->
これを実現するために、少なくとも11年間のデータを持つ企業からなる候補企業年度のサンプルを構築する。


```{r}
#| eval: false
test_sample <-
  acc_data_raw |>
  calc_accruals() |> # 関数を適用
  filter(# 条件を満たすデータを抽出
    lag_at > 0, sale > 0, ppegt > 0, !is.na(acc_raw),
    !is.na(d_rev), !is.na(d_rec), !is.na(ppegt)) |>
  group_by(gvkey) |> # gvkeyでグループ化
  filter(n() >= 11) |> # 11観測値以上のデータを持つ企業年を抽出
  ungroup() |> # グループ化を解除
  arrange(gvkey, fyear) |> # gvkeyとfyearで並び替え
  select(gvkey, fyear) # 変数を選択
```

<!-- Most of our analysis will focus on a single random sample of 1000 firms.  -->
ほとんどの分析は、1000社のランダムサンプルに焦点を当てる。
<!-- For each of these 1000 firms, we select a single fiscal year for which we set part to TRUE.  -->
これらの1000社の各企業について、partをTRUEに設定する1つの会計年度を選択する。
<!-- Because we use the lagged value of accruals for the DeAngelo Model, we constrain the random choice to be any year but the first year. -->
DeAngeloモデルでは総アクルーアルの前期の値を使用するため、ランダム選択を最初の年以外の任意の年に制限する。


```{r}
#| eval: false
set.seed(2022) # 乱数のシードを設定

sample_1_firm_years <-
  test_sample |>
  mutate( # ランダムに1つの会計年度を選択
    rand = rnorm( # 正規分布から乱数を生成
      n = nrow(pick(everything())) # 行数分の乱数を生成
      )) |>
  group_by(gvkey) |>
  filter(rand == min(rand),  # 最小の乱数を持つ行を抽出
         fyear > min(fyear) # 最初の年以外の行を抽出
         ) |>
  ungroup() |> # グループ化を解除
  top_n(1000, wt = rand) |> # 乱数の値が最小の1000行を抽出
  select(gvkey, fyear) |> # 変数を選択
  mutate(part = TRUE) # partをTRUEに設定
```

<!-- To create sample_1, we use two joins.  -->
`sample_1`を作成するために、2つの結合を使用する。
<!-- The first join — a semi_join() — is by gvkey and ensures that we draw those firm-years in test_sample that have been selected in sample_1_firm_years.  -->
最初の結合は、`gvkey`による`semi_join()`であり、`sample_1_firm_years`で選択された企業年度を持つ`test_sample`の企業年度を抽出する。
<!-- The second join — a left_join() — is by gvkey and fyear and has the effect of adding the part indicator from sample_1_firm_years to the data for the applicable firm-years.  -->
2番目の結合は、`gvkey`と`fyear`による`left_join()`であり、`sample_1_firm_years`からのpart指標を該当する企業年度のデータに追加する。
<!-- Most firm-years will not be found in sample_1_firm_years and the final step uses coalesce() to set part to FALSE for firm-years missing from sample_1_firm_years. -->
ほとんどの企業年度は`sample_1_firm_years`には見つからないため、最終ステップでは、`sample_1_firm_years`に欠落している企業年度に対して`part`を`FALSE`に設定するために`coalesce()`を使用する。


```{r}
#| eval: false
sample_1 <-
  test_sample |>
  semi_join(sample_1_firm_years, by = "gvkey") |> # セミ結合
  left_join(sample_1_firm_years, by = c("gvkey", "fyear")) |> # 左結合
  mutate(part = coalesce(part, FALSE))
```


<!-- We combine the data on part for our sample firm-years with the Compustat data in acc_data_raw to form merged_sample_1.4 -->
サンプル企業年度のpartデータをCompustatデータの`acc_data_raw`と組み合わせて`merged_sample_1`を作成する。[^4]

```{r}
#| eval: false
merged_sample_1 <-
  sample_1 |>
  inner_join(acc_data_raw, by = c("gvkey", "fyear")) # 内部結合
```

[^4]: Our sampling approach deviates from that in Dechow et al. (1995), where firm-years are selected (without replacement) subject to the constraint that “a firm-year is not selected if its inclusion in the random sample leaves less than ten unselected observations for the estimation period.” One important difference is that the approach in Dechow et al. (1995) could lead to a firm having two years of earnings management. There seems to be little upside in this, while our approach is much simpler to code and unlikely to impact results in a significant way.

<!-- If we were conducting a simple study of observed earnings management, it would be natural to calculate our measures of earnings management and then proceed to our analyses.  -->
観察された利益マネジメントの単純な研究を行う場合、利益マネジメントの尺度を計算してから分析に進むのが自然である。
<!-- However, in our analysis here we will — like Dechow et al. (1995) — be manipulating accounting measures ourselves and doing so will require us to recalculate earnings management measures and inputs to these, such as measures of total accruals.  -->
しかし、ここでの分析では、Dechow et al. (1995) のように、自分で会計尺度を操作することになるため、利益マネジメントの尺度や総アクルーアルの尺度などの入力を再計算する必要がある。
<!-- To facilitate this process, we embed the calculations for all five earnings management measures in the function get_nda() below. -->
このプロセスを容易にするために、以下の関数`get_nda()`に5つの利益マネジメント尺度の計算を埋め込む。[^5]
<!-- Note that we use reframe() in place of summarize() because the former does not assume that the result will be a single row for each group. -->
`summarize()`の代わりに`reframe()`を使用していることに注意する。`reframe()`は、結果が各グループごとに1行であるとは限らないためである。

[^5]: We put `fit_jones()` and `fit_mod_jones()` outside the function for reasons that will become clear if you attempt the exercises.


```{r}
# ジョーンズモデル
fit_jones <- function(df) {
  fm <- lm(acc_at ~ one_at + d_rev_at + ppe_at - 1,
           data = df, model = FALSE, subset = !part)

  df |>
    mutate(nda_jones = predict(fm, newdata = df),
           da_jones = acc_at - nda_jones) |>
    select(fyear, nda_jones, da_jones)
}

# 修正ジョーンズモデル
fit_mod_jones <- function(df) {
  fm <- lm(acc_at ~ one_at + d_rev_alt_at + ppe_at - 1,
           data = df, model = FALSE, subset = !part)
  df |>
    mutate(nda_mod_jones = predict(fm, newdata = df),
           da_mod_jones = acc_at - nda_mod_jones) |>
    select(fyear, nda_mod_jones, da_mod_jones)
}

# 非裁量的アクルーアルを計算
get_nda <- function(df) {

  df_mod <-
    df |>
    calc_accruals() |> # 総アクルーアルを計算
    mutate(sic2 = str_sub(as.character(sic), 1, 2),
           acc_at = acc_raw / lag_at,
           one_at = 1 / lag_at,
           d_rev_at = d_rev / lag_at,
           d_rev_alt_at = (d_rev - d_rec) / lag_at,
           ppe_at = ppegt / lag_at) |>
    group_by(sic2) |> # sic2でグループ化
    mutate(
      acc_ind = median(if_else(part, NA, acc_at), na.rm = TRUE)) |>
    ungroup()
  # ヒーリーのモデル
  da_healy <-
    df_mod |>
    group_by(gvkey) |>
    arrange(fyear) |>
    mutate(nda_healy = mean(if_else(part, NA, acc_at), na.rm = TRUE),
           da_healy = acc_at - nda_healy,
           nda_deangelo = lag(acc_at),
           da_deangelo = acc_at - nda_deangelo) |>
    ungroup() |>
    select(gvkey, fyear, part, nda_healy, da_healy, nda_deangelo,
           da_deangelo)
  # ジョーンズモデル
  df_jones <-
    df_mod |>
    nest_by(gvkey) |>
    reframe(fit_jones(data))
  # 修正ジョーンズモデル
  df_mod_jones <-
    df_mod |>
    nest_by(gvkey) |>
    reframe(fit_mod_jones(data))

  # 産業モデル
  fit_industry <- function(df) {
    fm <- lm(acc_at ~ acc_ind, data = df, model = FALSE, subset = !part)

    df |>
      mutate(nda_industry = suppressWarnings(predict(fm, newdata = df)),
             da_industry = acc_at - nda_industry) |>
      select(fyear, nda_industry, da_industry)
  }
  # 産業モデルのnda
  df_industry <-
    df_mod |>
    nest_by(gvkey) |>
    reframe(fit_industry(data))

  da_healy |>
    left_join(df_jones, by = c("gvkey", "fyear")) |>
    left_join(df_mod_jones, by = c("gvkey", "fyear")) |>
    left_join(df_industry, by = c("gvkey", "fyear"))
}
```

<!-- Applying get_nda() to our main sample (merged_sample_1) to create reg_data for further analysis requires just one line: -->
`get_nda()`をメインサンプル（`merged_sample_1`）に適用してさらなる分析のための`reg_data`を作成するには、1行だけで済む。


```{r}
#| eval: false
reg_data <- get_nda(merged_sample_1)
```




## Results under the null hypothesis: Random firms

Table 1 of Dechow et al. (1995) presents results from regressions of discretionary accruals on $PART$ for each of the five models.
For each model, three rows are provided.
The first row provides summary statistics for the estimated coefficients on $PART$ from firm-specific regressions for the 1000 firms in the sample.
The second and third rows provide summary statistics on the estimated standard errors of the coefficients on $PART$ and t-statistic testing the null hypothesis that the coefficients on $PART$ are equal to zero.

To facilitate creating a similar table, we make two functions.
The first function - `fit_model()` - takes a data frame and, for each firm, regresses the measure of discretionary accruals corresponding to measure on the part variable, returning the fitted models.
As we did in Chapter 14, we use `!!` to distinguish the measure supplied to the function from measure found in df.[^6]

[^6]: aa


```{r function_fit_model}
fit_model <- function(df, measure = "healy") {
  df |>
    nest_by(gvkey) |>
    summarize(model = list(lm(as.formula(str_c("da_", measure, " ~ part")),
                              model = FALSE, data = data)),
              .groups = "drop") |>
    mutate(measure = !!measure)
}
```

The second function - `multi_fit()` - runs `fit_model()` for all five models, returning the results as a data frame.


```{r function_multi_fit}
multi_fit <- function(df) {
  models <- c("healy", "deangelo", "jones", "mod_jones", "industry")
  models |>
    map(\(x) fit_model(df, x)) |>
    list_rbind()
}
```


With these functions in hand, estimating firm-specific regressions for the five models requires a single line of code.


```{r}
#| eval: false
results <- multi_fit(reg_data)
```

The returned results comprise three columns: gvkey, model, and type, with model being the fitted model for the firm and model indicated by gvkey and type. Note that model is a list column and contains the values returned by lm(). We can interrogate the values stored in model to extract whatever details about the regression we need.


```{r}
#| eval: false
head(results)
```

We will use tidy() to extract the coefficients, standard error, t-statistics, and p-values in each fitted model as a data frame. For Table 16.1 (our version of Table 1 of Dechow et al. (1995)), we are only interested in the coefficient on part (i.e., the one labelled partTRUE) and thus can discard the other row (this will be the constant of each regression) and the column term in the function get_stats() that will be applied to each model.


```{r function_get_stats}
get_stats <- function(fm) {
  fm |>
    tidy() |>
    filter(term == "partTRUE") |>
    select(-term)
}
```

The function table_1_stats() calculates the statistics presented in the columns of Table 1 of Dechow et al. (1995).


```{r dechow_tab01}
#| eval: false
table_1_stats <- function(x) {
  tibble(mean = mean(x, na.rm = TRUE),
         sd = sd(x, na.rm = TRUE),
         q1 = quantile(x, p = 0.25, na.rm = TRUE),
         median = median(x, na.rm = TRUE),
         q3 = quantile(x, p = 0.75, na.rm = TRUE))
}
```

To produce Table 16.1, our version of Table 1 of Dechow et al. (1995), we use map() from the purrr library to apply get_stats() to each model, then unnest_wider() and pivot_longer() (both from the tidyr package) to arrange the statistics in a way that can be summarized to create a table.


```{r}
#| eval: false
results |>
  mutate(stats = map(model, get_stats)) |>
  unnest_wider(stats) |>
  pivot_longer(estimate:statistic, names_to = "stat") |>
  group_by(measure, stat) |>
  summarize(table_1_stats(value), .groups = "drop")
```

Table 2 of Dechow et al. (1995) presents rejection rates for the null hypothesis of no earnings management in the $PART$ year for the five measures. Given that Sample 1 comprises 1000 firms selected at random with the year in each case also being selected at random, we expect the rejection rates to equal the size of the test being used (i.e., either 5% or 1%). To help produce a version of Table 2 of Dechow et al. (1995), we create h_test(), which extracts statistics from fitted models and returns data on rejection rates for different hypotheses and different size tests.


```{r fuction_h_test}
 h_test <- function(fm) {
  coefs <- coef(summary(fm))

  if (dim(coefs)[1]==2) {
    t_stat <- coefs[2 ,3]
    df <- fm$df.residual

    tibble(neg_p01 = pt(t_stat, df, lower = TRUE) < 0.01,
           neg_p05 = pt(t_stat, df, lower = TRUE) < 0.05,
           pos_p01 = pt(t_stat, df, lower = FALSE) < 0.01,
           pos_p05 = pt(t_stat, df, lower = FALSE) < 0.05)
  } else {
    tibble(neg_p01 = NA, neg_p05 = NA, pos_p01 = NA, pos_p05 = NA)
  }
}
```


We then map this function to the models in results and store the results in test_results.




```{r}
#| eval: false
test_results <-
  results |>
  mutate(map_dfr(model, h_test))
```

Using, test_results, Table 16.2 provides our analogue of Table 2 of Dechow et al. (1995).


```{r}
#| eval: false
test_results |>
  group_by(measure) |>
  summarize(across(matches("p0"),
                   \(x) mean(x, na.rm = TRUE)))
```

Dechow et al. (1995) indicate cases where the Type I error rate is statistically significantly different from the size of the test using a “two-tailed binomial test”. This may be confusing at an initial reading, as the statistics presented in Table 2 of Dechow et al. (1995) are—like those in Table 16.2—based on one-sided tests. But note that whether we are conducting one-sided tests or two-sided tests of the null hypothesis, we should expect rejection rates to equal the size of the test (e.g., 5% or 1%) if we have constructed the tests correctly. For example, if we run 1000 tests with a true null and set the size of the test at 5%, then rejecting the null hypothesis 10 times (1%) or 90 times (9%) will lead to rejection of the null (meta-)hypothesis that our test of our null hypothesis is properly sized, as the following p-values confirm. The function binom.test() provides the p-value that we need here.


```{r}
#| eval: false
binom.test(x = 10, n = 1000, p = 0.05)$p.value

binom.test(x = 90, n = 1000, p = 0.05)$p.value
```

We embed binom.test() in a small function (binom_test()) that will be convenient in our analysis. Without an a priori reason to expect over-rejection or under-rejection, it makes sense to consider two-sided test statistics against a null hypothesis that the rejection rate equals the size of the test. Such statistics are returned by binom.test() by default.


```{r}
#| eval: false
binom_test <- #| function(x, p) {
  x <- x[!is.na(x)]
  binom.test(sum(x), length(x), p = p)$p.value
}
```

We apply binom_test() to the test results above, adjusting the p argument based on the size of the test used in each case and report the results in Table 16.3.


```{r}
#| eval: false
test_results |>
  group_by(measure) |>
  summarize(neg_p01 = binom_test(neg_p01, p = 0.01),
            neg_p05 = binom_test(neg_p05, p = 0.05),
            pos_p01 = binom_test(pos_p01, p = 0.01),
            pos_p05 = binom_test(pos_p05, p = 0.05))
```

Turning to the Jones Model and the Modified Jones Model, it is quite clear that we are over-rejecting the (true) null hypothesis. One possible explanation for this over-rejection is provided by footnote 11 of Dechow et al. (1995, p. 204):

> The computation of the standard error of $\hat{b}_j$  requires special attention because the measures of discretionary accruals in the event period (estimation period) are prediction errors (fitted residuals) from a first-pass estimation process. An adjustment must therefore be made to reflect the fact that the standard errors of the prediction errors are greater than the standard errors of the fitted residuals. Likewise, the degrees of freedom in the t-test must reflect the degrees of freedom used up in the first-pass estimation. This can be accomplished by … estimating a single-stage regression that includes both $PART$ and the determinants of nondiscretionary accruals.

The invocation of a single-stage regression might remind some readers of the Frisch-Waugh-Lovell theorem, which we discussed in Section 3.3. But an important element of the single-stage regression approach suggested by the Frisch-Waugh-Lovell theorem is that the first- and second-stage regressions that are shown by the theorem to be equivalent have the same observations in both stages. In contrast, the first stages of the Jones Model and Modified Jones Model approaches used by Dechow et al. (1995) use only the estimation sample (i.e., they exclude the test firm-year of primary interest). But this is not an issue here because the single-stage regression invoked by Dechow et al. (1995) is actually that attributed to Salkever (1976).

Salkever (1976) demonstrates that the estimated value of discretionary accruals in the test year can be obtained by running a single regression including both the estimation and test periods and a dummy variable for the test year. The prediction error for the test observation (i.e., the estimated discretionary accruals for the test firm-year) will be equal to the coefficient on the $PART$ variable and the correct standard error for this prediction will be the standard error of that coefficient.

Because the Salkever (1976) approach is infrequently used in accounting research, but seems quite relevant in a number of settings, we spend some time exploring it in the discussion questions below. (Note that in the following, to keep things manageable, we pull a single GVKEY value at random from our sample. You may need to modify this code to ensure that you are drawing the GVKEY of a firm in your sample, which may differ from ours.)

To keep things simple, we pull one firm from our sample.


```{r}
#| eval: false
df_test <-
  merged_sample_1 |>
  filter(gvkey == "001304")
```

<!-- We then create the variables needed to run the Jones Model. -->
次に、Jonesモデルを実行するために必要な変数を作成する。


```{r}
#| eval: false
df_mod <-#|
  df_test |>
  calc_accruals() |>
  mutate(acc_at = acc_raw / lag_at,
         one_at = 1 / lag_at,
         d_rev_at = d_rev / lag_at,
         d_rev_alt_at = (d_rev - d_rec) / lag_at,
         ppe_at = ppegt / lag_at) |>
  ungroup()
```

<!-- We then fit a (differently) modified Jones Model on the estimation sample, which we store in fm1a.7 -->
次に、推定サンプルに（異なる）修正Jonesモデルを適合し、`fm1a`に格納する。[^7]

[^7]: 777



```{r}
#| eval: false
fm1a <- lm(acc_at ~ one_at + d_rev_at + ppe_at,
          data = df_mod, subset = !part)
```

<!-- We can then calculate non-discretionary accruals for the full sample using predict().  -->
次に、`predict()`を使用して全サンプルの非裁量的アクルーアルを計算することができる。
<!-- Again we use pick(everything()) for the reasons discussed in Chapter 13. -->
13章で議論した理由から、再び`pick(everything())`を使用する。

```{r}
#| eval: false
res1 <-
  df_mod |>
  mutate(nda_jones = predict(fm1a, newdata = pick(everything()))) |>
  select(fyear, part, acc_at, nda_jones) |>
  mutate(da_jones = acc_at - nda_jones)
```

<!-- Finally, we can estimate the regression of discretionary accruals on the $PART$ variable and store the results in `fm2a`. -->
最後に、総アクルーアルを $PART$ 変数に対して回帰し、その結果を`fm2a`に格納する。

```{r}
#| eval: false
fm2a <- lm(da_jones ~ part, data = res1)
```

<!-- To implement the approach suggested by Salkever (1976) - and used by Dechow et al. (1995) - we run a single regression on the entire sample with the addition of the $PART$ indicator and store the result in `fm2`. -->
Salkerver (1976) が提案したアプローチを実装するために、Dechow et al. (1995) が使用したように、サンプル全体に $PART$ 指標を追加して単一の回帰を実行し、その結果を`fm2`に格納する。


```{r}
#| eval: false
fm2 <- lm(acc_#| at ~ one_at + d_rev_at + ppe_at + part,
          data = df_mod)
```

<!-- ## Results under the null hypothesis: Extreme performance -->
## 帰無仮説下の結果：極端なパフォーマンス


<!-- Table 3 of Dechow et al. (1995) presents results from regressions using the second set of samples (“samples of 1000 firm-years randomly selected from firm-years experiencing extreme financial performance”).  -->
Dechow et al. (1995)のTable 3は、第2のサンプル（「極端な財務パフォーマンスを経験している企業年度からランダムに選択された1000企業年度のサンプル」）を使用した回帰の結果を示している。
<!-- Table 3 is analogous to Table 2, for which we provided parallel results in Table 16.2. -->
Table 3はTable 2に類似しており、Table 16.2で平行な結果を提供した。
<!-- We leave reproduction of a parallel analysis to that reported in Table 3 of Dechow et al. (1995) as an exercise for the reader and merely provide code producing a sample that can be used for that purpose. -->
Dechow et al. (1995)のTable 3で報告された平行な分析の再現は、読者にとっての演習として残し、その目的に使用できるサンプルを生成するコードのみを提供する。
<!-- The following code proceeds in four steps.  -->
次のコードは、4つのステップで進行する。
<!-- First, we create earn_deciles, which contains a variable earn_dec that sorts firm-years into earnings deciles for all firms meeting the sample criteria (i.e., those in test_sample). -->
最初に、`earn_deciles`を作成する。これには、サンプル基準を満たすすべての企業（つまり、`test_sample`に含まれる企業）を利益十分位に並べる変数`earn_dec`が含まれている。


```{r}
#| eval: false
earn_deciles <-
  acc_data_raw |>
  semi_join(test_sample, by = c("gvkey", "fyear")) |>
  group_by(gvkey) |>
  arrange(fyear) |>
  mutate(earn = ib / lag(at)) |>
  ungroup() |>
  mutate(earn_dec = ntile(earn, 10)) |>
  select(gvkey, fyear, earn_dec)
```

<!-- Second, we create sample_2_firm_years, which selects firm-years from the top earnings decile (subject to the constraint that the year is not the first year for the firm, as a prior year is required for the DeAngelo Model). -->
第2に、`sample_2_firm_years`を作成する。これは、最上位の利益十分位から企業年度を選択する（DeAngeloモデルには前年が必要なため、企業の最初の年ではないことが制約として設定されている）。
<!-- When a firm has more than one firm-year in the top earnings decile, one of those firm-years is selected at random. -->
企業が最上位の利益十分位に複数の企業年度を持っている場合、そのうちの1つの企業年度がランダムに選択される。



```{r}
#| eval: false
sample_2_firm_years <-
  earn_deciles |>
  filter(earn_dec == 10) |>
  select(gvkey, fyear) |>
  mutate(rand = rnorm(n = nrow(pick(everything())))) |>
  group_by(gvkey) |>
  filter(rand == min(rand), fyear > min(fyear)) |>
  ungroup() |>
  top_n(1000, wt = rand) |>
  select(gvkey, fyear) |>
  mutate(part = TRUE)
```

<!-- Third, we create sample_2 by pulling firm-years from test_sample for firms found in sample_2_firm_years and then pulling in the firm-years where part is TRUE based on the value of part from sample_2_firm_years and then setting the value of part to FALSE when it is missing (i.e., not found on sample_2_firm_years). -->
第3に、`sample_2`を作成する。これは、`sample_2_firm_years`に見つかる企業の企業年度を`test_sample`から引き出し、`sample_2_firm_years`の`part`の値に基づいて`part`が`TRUE`の企業年度を引き出し、`part`が欠落している場合（つまり、`sample_2_firm_years`に見つからない場合）は`part`の値を`FALSE`に設定する。




```{r}
#| eval: false
sample_2 <-
  test_sample |>
  semi_join(sample_2_firm_years, by = "gvkey") |>
  left_join(sample_2_firm_years, by = c("gvkey", "fyear")) |>
  mutate(part = coalesce(part, FALSE))
```

<!-- Finally, we create merged_sample_2 — the analogue of merged_sample_1 — by merging sample_2 with the underlying accounting data in acc_data_raw. ???-->
最後に、`merged_sample_2`を作成する。これは、`merged_sample_1`のアナログであり、`sample_2`を`acc_data_raw`の基礎となる会計データとマージすることで作成される。


```{r}
#| eval: false

merged_sample_2 <-
  sample_2 |>
  inner_join(acc_data_raw, by = c("gvkey", "fyear"))
```

<!-- Table 3 of Dechow et al. (1995) actually involves two samples.  -->
Dechow et al. (1995)のTable 3は、実際には2つのサンプルを含んでいる。
<!-- One sample is similar to the above and a second sample would be based on the above, but with `filter(earn_dec == 1)` being used in the creation of `sample_2_firm_years`. -->
1つのサンプルは上記と似ており、2つ目のサンプルは上記をベースにして、`sample_2_firm_years`の作成に`filter(earn_dec == 1)`を使用している。
<!-- Table 4 of Dechow et al. (1995) is similar, but is based on deciles of cash flow from operations, where cash flow from operations is calculated using earnings and accruals, as cash flow statements were not required for most of the sample period in Dechow et al. (1995). -->
Dechow et al. (1995)の表4と似ているが、これは営業活動によるキャッシュフローの十分位に基づいている。
Dechow et al. (1995)のほとんどのサンプル期間ではキャッシュフロー計算書が要求されておらず、営業活動によるキャッシュフローは利益とアクルーアルを使用して計算された。


<!-- ## Discussion questions and exercises -->
## 議論の質問と演習

<!-- 1. What interpretation do Dechow et al. (1995) provide for their Table 1 results? -->
1. Dechow et al. (1995)は、Table 1の結果に対してどのような解釈を提供しているか。

<!-- 2. Compare the results in Table 16.1 with those in Table 1 of Dechow et al. (1995). What differences appear to be significant? -->
2. Table 16.1の結果とDechow et al. (1995)のTable 1の結果を比較して、どのような違いが重要であると思われるか。

<!-- 3. Compare the values in the standard deviation column of Table 1 of Dechow et al. (1995) with other statistics. Do these differences make sense? Or do they suggest anomalies in the underlying data? -->
3. Dechow et al. (1995)のTable 1の標準偏差列の値を他の統計量と比較しよう。
これらの違いは理にかなっていますか？それとも、基礎データに異常があることを示唆しているか？

<!-- 4. Compare the values in the standard deviation column of the “earnings management” rows of Table 1 of Dechow et al. (1995) with the values in the mean column of the standard error rows.  -->
4. Dechow et al. (1995)の表1の「earnings management」行の標準偏差列の値を、標準誤差行の平均列の値と比較しなさい。
<!-- What is the relationship between these values? What would you expect the relationship between these values to be? Do you observe similar relations in Table 16.1? -->
これらの値の関係は何か？これらの値の関係はどのようになると予想されるのか？Table 16.1でも同様の関係を観察できるか？

<!-- 5. Focusing on the Healy Model, DeAngelo Model, and the Industry Model, compare the rejection rates in Table 16.2 with those presented in Table 2 of Dechow et al. (1995).  -->
5. Healyモデル、DeAngeloモデル、産業モデルに焦点を当て、Table 16.2の棄却率をDechow et al. (1995)のTable 2で提示されたものと比較してください。
<!-- What might explain any differences? Could these be attributed to differences between our results in Table 16.1 and those reported in Table 1 of Dechow et al. (1995)? Or do you expect that these differences have another cause? -->
どのような違いが説明されるか？これらはTable 16.1の結果とDechow et al. (1995)のTable 1で報告された結果との違いに起因すると考えられるか？それとも、これらの違いには別の原因があると予想されるか？

<!-- 6. How do you interpret the results from binom_test() reported in Table 16.3? Does it make sense to interpret each of the columns independent of the others? -->
6. Table 16.3に報告されたbinom_test()の結果をどのように解釈できるか？
各列を他の列とは独立して解釈するのは意味があるのか？

<!-- 7. Confirm that the coefficient on $PART$ from the regression in fm2a can be recovered from the regression in fm2. Are the standard errors the same? -->
7. `fm2a`の回帰の $PART$ の係数が`fm2`の回帰から回復できることを確認しなさい。標準誤差は同じか？

<!-- 8. Modify the code above to check that the same holds for the Modified Jones Model. -->
8. 上記のコードを修正して、修正ジョーンズモデルについても同様のことが成立するか確認しなさい。

<!-- 9. We described the Jones Model above as “a (differently) modified Jones Model”.  -->
9. 上で説明したジョーンズモデルを「(異なる)修正ジョーンズモデル」と呼ぶ。
<!-- In what way is the model different from the Jones Model estimated in fit_jones() above? Does the Salkever (1976) equivalence hold if we use the Jones Model from `fit_jones()`?  -->
このモデルは、上記の`fit_jones()`で推定されたジョーンズモデルとどのように異なるか？`fit_jones()`からのジョーンズモデルを使用した場合、Salkever (1976)の同等性は成立するか？
<!-- If so, why? If not, how might this affect how you would use the Jones Model and the Salkever (1976) approach?  -->
成立する場合、なぜか？成立しない場合、ジョーンズモデルとSalkever (1976)アプローチの使用方法にどのように影響するか？
<!-- (For example, do we expect the “(differently) modified Jones Model” to produce materially different results from the Jones Model?) -->
（たとえば、「(異なる)修正ジョーンズモデル」は、ジョーンズモデルと実質的に異なる結果を生じると予想されるか？）

<!-- 10. Do the issues related to a first and second stage apply to either the Healy Model or the DeAngelo Model or both?  -->
10. 一段目と二段目に関連する問題は、HealyモデルまたはDeAngeloモデルのどちらか、または両方に適用されるか？
<!-- If so, could we apply the Salkever (1976) approach to address these issues?  -->
もしそうなら、Salkever (1976)アプローチを適用してこれらの問題に対処できるか？
<!-- If not, are there “one-stage” equivalents to the Healy Model and DeAngelo Model approaches as implemented above? -->
そうでない場合、上記で実装されたHealyモデルとDeAngeloモデルのアプローチに対する「一段階」の同等物はあるか？

<!-- 11. Produce an equivalent of Table 3 from Dechow et al. (1995) by adapting the code used above to create merged_sample_2 and Table 16.2. (Challenge version: Implement the approach of Salkever (1976) in doing so.) -->
11. 上記で使用したコードを適応して、merged_sample_2とTable 16.2を作成することで、Dechow et al. (1995)のTable 3の同等物を作成しなさい。（チャレンジバージョン：Salkever (1976)のアプローチを実装しなさい。）

<!-- 12. Produce an equivalent of Table 4 from Dechow et al. (1995) by adapting the code used above to create merged_sample_2 and Table 16.2. -->
12. 上記で使用したコードを適応して、merged_sample_2とTable 16.2を作成することで、Dechow et al. (1995)のTable 4の同等物を作成しなさい。





## Power of tests of earnings management


<!-- The final analysis of Dechow et al. (1995) that we consider here relates to the third set of samples considered by Dechow et al. (1995, p. 200), namely “samples of 1000 randomly selected firm-years in which a fixed and known amount of accrual manipulation has been artificially introduced.” -->
ここで考慮するDechow et al. (1995)の最終分析は、Dechow et al. (1995, p.200)が考慮したサンプルの3番目のセットに関連しており、「固定された既知の額のアクルーアル操作が人為的に導入された1000のランダムに選択された企業年度のサンプル」である。
<!-- Figure 4 of Dechow et al. (1995) presents power functions for three different forms of earnings management, the five measures of earnings management, and levels of induced earnings management from zero to 100% of total assets. -->
Dechow et al. (1995)の図4は、3つの異なる形式の利益管理、5つの利益管理尺度、および総資産の0から100%までのレベルの誘発された利益マネジメントのパワー関数を示している。
<!-- To implement a “fixed and known amount of accrual manipulation”, we use the function manipulate(), which takes a data set with the required variables from Compustat (e.g., gvkey, fyear, sale, at), an argument for the level of earnings management as a percentage of lagged total assets, and an argument for the type of earnings management, which can be "expense", "revenue" or "margin", as described in Dechow et al. (1995). -->
「固定された既知の額のアクルーアル操作」を実装するために、Compustatから必要な変数を持つデータセット（例：gvkey、fyear、sale、at）を取る関数`manipulate()`を使用する。この関数は、前年度の総資産の割合としての利益管理のレベルの引数と、Dechow et al. (1995)で説明されているように、利益管理のタイプとして"expense"、"revenue"、または"margin"のいずれかを取る引数を取る。



```{r function_manipulate}
manipulate <- function(df, level = 0, type) {
  df <-
    df |>
    group_by(gvkey) |>
    arrange(datadate) |>
    mutate(ni_ratio = median(if_else(part, NA, ni / sale), na.rm = TRUE),
           lag_at = lag(at),
           manip_amt = lag_at * level,
           manip_amt_gross = manip_amt / ni_ratio)

  if (type == "expense") {
    df |>
      mutate(lct = if_else(part, lct - manip_amt, lct)) |>
      ungroup()
  } else if (type == "revenue") {
    df |>
      mutate(sale = case_when(part ~ sale + manip_amt,
                              lag(part) ~ sale - manip_amt,
                              .default = sale),
             rect = if_else(part, rect + manip_amt, rect),
             act = if_else(part, act + manip_amt, act)) |>
      ungroup()
  } else if (type == "margin") {
    df |>
      mutate(sale = case_when(part & ni_ratio > 0 ~
                                sale + manip_amt_gross,
                              lag(part) & ni_ratio > 0 ~
                                sale - manip_amt_gross,
                              .default = sale),
             rect = if_else(part & ni_ratio > 0,
                            rect + manip_amt_gross, rect),
             act = if_else(part & ni_ratio > 0,
                           act + manip_amt_gross, act),
             lct = if_else(part & ni_ratio > 0,
                           lct + manip_amt_gross - manip_amt, lct)) |>
      ungroup()
  } else {
    df |>
      ungroup()
  }
}
```

<!-- We use the manipulate() function above and apply it to levels of earning management from 0 to 100% of lagged total assets for each of the three types.  -->
上記の`manipulate()`関数を使用し、各タイプについて、総資産の前年度比率の0から100%までのレベルの利益管理を適用する。
<!-- The result from the step above is fed to get_nda() from above, the results of which are then fed to multi_fit() to calculate the results of regressing discretionary accruals on the $PART$ variable.  -->
上記のステップの結果は、上記の`get_nda()`に供給され、その結果は`multi_fit()`に供給され、総アクルーアルを$PART$変数に回帰した結果を計算する。
<!-- The result of these steps is stored in the data frame named manip_df. -->
これらのステップの結果は、`manip_df`というデータフレームに格納される。


:::{.callout-important}
<!-- Note that creating `manip_df` takes some time. -->
`manip_df`の作成には時間がかかるため、
<!-- The exercises below do not require this code to be run. -->
以下の演習では、このコードを実行する必要はない。
<!-- In addition to processing time, this code is quite memory-intensive—requiring more than 10 GB of RAM. -->
処理時間に加えて、このコードはかなりのメモリを消費する。メモリは10GB以上必要となる。
<!-- So, if you have less than about 16 GB of RAM, this code might require modification to run smoothly on your machine. -->
したがって、RAMが約16GB未満の場合、このコードをスムーズに実行するには修正が必要かもしれない。
:::


```{r}
#| eval: false
plan(multisession)

manip_df <-
  expand_grid(level = seq(from = 0, to = 1, by = 0.1),
              manip_type = c("expense", "revenue", "margin")) |>
  mutate(data = future_map2(level, manip_type,
                            \(x, y) manipulate(merged_sample_1, x, y))) |>
  mutate(accruals = future_map(data, get_nda)) |>
  mutate(results = future_map(accruals, multi_fit)) |>
  select(-data, -accruals) |>
  system_time()
```

<!-- With results from regressions for various values of level, the three values of `manip_type`, and the five models (`manip_type`) stored in `manip_df`, we can create plots like those presented in Figure 4 of Dechow et al. (1995) using the following code.  -->
様々なレベル値での回帰の結果、3つの`manip_type`の値、および5つのモデル（`manip_type`）の結果が`manip_df`に格納されているため、以下のコードを使用して、Dechow et al. (1995)の図4に示されているようなプロットを作成できる。
<!-- We first create a function (`h_test_5()`) that takes a fitted model and returns a logical value indicating whether the null hypothesis is rejected at the 5% level. -->
まず、適合モデルを受け取り、5%の水準で帰無仮説が棄却されたかどうかを示す論理値を返す関数（`h_test_5()`）を作成する。


```{r function_h_test_5}
#| eval: false

h_test_5 <- function(fm) {

  coefs <- coef(summary(fm))

  if (dim(coefs)[1]==2) {
    t_stat <- coefs[2 ,3]
    df <- fm$df.residual
    pt(t_stat, df, lower = FALSE) < 0.05
  } else {
    NA
  }
}
```

The code below applies `h_test_5()` to each row of `manip_df` to calculate the proportion of firms for which the null is rejected for each value of (level, `manip_type`, measure).


:::{.callout-important}
<!-- Note that creating `power_plot_data` takes some time. -->
この`power_plot_data`の作成には時間がかかるため、
<!-- The exercises below do not require this code to be run. -->
以下の演習では、このコードを実行する必要はない。
<!-- In addition to processing time, this code is quite memory-intensive—requiring more than 10 GB of RAM. -->
処理時間に加えて、このコードはかなりのメモリを消費し、メモリは10GB以上必要となる。
<!-- So, if you have less than about 16 GB of RAM, this code might require modification to run smoothly on your machine. -->
したがって、RAMが約16GB未満の場合、このコードをスムーズに実行するには修正が必要かもしれない。
:::



```{r}
#| eval: false

plan(multisession)

power_plot_data <-
  manip_df |>
  unnest(results) |>
  group_by(level, manip_type, measure) |>
  mutate(rej_null = future_map_lgl(model, h_test_5)) |>
  summarize(prop_reject = mean(rej_null, na.rm = TRUE), .groups = "drop") |>
  system_time()
```

<!-- This data set is easily plotted using facet_grid(), with the results shown in Figure 16.1. -->
このデータセットは、facet_grid()を使用して簡単にプロットでき、その結果は図16.1に示されている。


```{r}
#| eval: false

power_plot_data |>
  ggplot(aes(x = level, y = prop_reject)) +
  geom_line() +
  facet_grid(measure ~ manip_type)
```

## Discussion questions

<!-- 1. How do the results in Figure 16.1 compare with those in Figure 4 of Dechow et al. (1995)? -->
1. 図16.1の結果は、Dechow et al. (1995)の図4と比較してどうだろうか？

<!-- 2. According to the SEC’s filing referenced above related to B&L, “B&L recognized, in contravention of GAAP and the Company’s own revenue recognition policies, $42.1 million of revenue, resulting in at least a $17.6 million, or 11%, overstatement of the net income originally reported for its 1993 fiscal year.”  -->
2. B&Lに関連する上記のSECの報告書によると、「B&Lは、GAAPおよび同社独自の収益認識方針に違反して、1993会計年度に報告された純利益の少なくとも11%、つまり$17.6百万ドルの純利益の過大報告をもたらす$42.1百万ドルの収益を認識した。」
  <!-- According to a subsequent SEC filing, B&L’s total assets for 1994 were $2,457,731,000 (it seems reasonable to assume that the 1993 value was not radically different from this).  -->
  後のSECの報告書によると、B&Lの1994年の総資産は$2,457,731,000ドルであった（1993年の値がこれと大きく異なると仮定するのは合理的でないと思われる）。
  <!-- Based on this information (plus any information in the SEC’s filing), which of Dechow et al. (1995)’s three categories did B&L’s earnings management fall into?  -->
  この情報（およびSECの報告書に含まれる情報）に基づいて、B&Lの収益管理はDechow et al. (1995)の3つのカテゴリのどれに該当するか？
  <!-- What is the approximate magnitude relative to the x-axes of the plots in Figure 4 of Dechow et al. (1995) (or the equivalent above)?  -->
  Dechow et al. (1995)の図4（または上記の図）のx軸に対する大きさはおおよそどれくらいか？
  <!-- Based on these data points, what is the approximate estimated probability of the various models detecting earnings management of this magnitude? -->
  これらのデータポイントに基づいて、この程度の収益管理を検出する各モデルの確率のおおよその推定値はどれくらいか？

<!-- 3. What do you view as the implications of the power analysis conducted above for research on earnings management?  -->
3. 上記で行われたパワー分析の研究に対する意味合いは何だと考えるか？
   <!-- Are these implications consistent with the extensive literature on earnings management subsequent to Dechow et al. (1995)?  -->
    これらの意味合いは、Dechow et al. (1995)以降の利益マネジメントに関する広範な文献と一致しているか？
   <!-- If so, explain why. If not, how would you reconcile the inconsistencies? -->
    そうであれば、その理由を説明してください。そうでない場合、どのようにして矛盾を調整しますか？

<!-- 4. Does each of the three forms of earnings management implemented in manipulate() above agree precisely with the corresponding description in Dechow et al. (1995, pp. 201–202)?  -->
4. Dechow et al. (1995, pp.201-202)における対応する説明と、上記のmanipulate()で実装された3つの収益管理の形式が正確に一致しているか？
  <!-- If not, does one approach seem more correct than the other? -->
  そうでない場合、どちらのアプローチがより正しいように見えるか？
  <!-- (Note that one issue arises with negative or zero net income ratio. How are such cases handled by Dechow et al. (1995) and by manipulate()?) -->
  (負の収益率やゼロの場合に問題が発生します。Dechow et al. (1995)と`manipulate()`はそのようなケースをどのように処理していますか？)
