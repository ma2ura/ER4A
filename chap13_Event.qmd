# イベント・スタディ

<!-- In previous chapters, we studied papers that have examined the reaction of financial markets to information.  -->
これまでの章では，金融市場が情報にどのように反応するかを調査した論文を学習した。
<!-- Chapter 10 covered Fama et al. (1969), which studied the adjustment of prices to the information in stock splits. -->
Chapter 10では，株式分割に関する情報への価格調整を研究したFama et al. (1969)を扱った。
<!-- Chapter 11 examined Ball and Brown (1968), which shows that market returns over a year are correlated with earnings news for the period. -->
Chapter 11では，Ball and Brown (1968)を取り上げ，1年間の市場リターンがその期間の収益ニュースと相関していることを示した。
<!-- Chapter 12 studied Beaver (1968), which shows that volume and price volatility increase around earnings announcements. -->
Chapter 12では，Beaver (1968)を学習し，収益発表の周辺で取引量と価格の変動が増加することを示した。

<!-- The decades since those early papers have seen significant evolution in how researchers study the market reaction to information and this chapter provides an introduction to current event-study methods. -->
これらの初期の論文以来の数十年間で，研究者が情報に対する市場の反応をどのように研究するかについては，大きな進化が見られ，本章では現在のイベント・スタディの方法について紹介する。

:::{.callout-tip}
<!-- The code in this chapter uses the packages listed below.  -->
この章のコードは，以下のパッケージを使用しています。
<!-- For instructions on how to set up your computer to use the code found in this book, see Section 1.2.  -->
この書籍のコードを使用するためのコンピュータの設定方法については，1.2節を参照してください。
<!-- Quarto templates for the exercises below are available on GitHub. -->
以下の演習のためのQuartoテンプレートはGitHubで入手できます。
:::


```{r}
pacman::p_load(tidyverse, DBI, farr, modelsummary, dbplyr)
```

<!-- ## Overview -->
## 概要

<!-- MacKinlay (1997, p. 13) defines an event study as one that, “using financial market data … measures the impact of a specific event on the value of a firm.  -->
MacKinlay (1997, p. 13)によると，**イベント・スタディ**(event study)は，「財務市場データを使用して…特定のイベントが企業の価値に与える影響を測定するものである。
<!-- The usefulness of such a study comes from the fact that, assuming highly efficient markets, the effects of an event will be reflected immediately in security prices.1  -->
このような研究の有用性は，非常に効率的な市場を仮定すると，イベントの影響はすぐに証券価格に反映されるという事実に由来する。[^1]
<!-- Thus a measure of the event’s economic impact can be constructed using security prices observed over a relatively short time period.” -->
したがって，比較的短い期間に観察された証券価格を使用して，イベントの経済的影響を測定することができる。」ものとして定義している。

<!-- MacKinlay (1997, p.14) continues: “In the late 1960s seminal studies by Ray Ball and Philip Brown (1968) and Eugene Fama et al. (1969) introduced the methodology that is essentially the same as that which is in use today.  -->
MacKinlay (1997, p.14)では，「1960年代後半にRay BallとPhilip Brown（1968）およびEugene Fama et al. (1969)による画期的な研究が行われ，その方法論は基本的に現在使用されているものとほぼ同じである。
<!-- Ball and Brown considered the information content of earnings, and Fama et al. (1969) studied the effects of stock splits after removing the effects of simultaneous dividend increases.” -->
Ball and Brown (1968)は利益の情報内容を考慮し， Fama et al. (1969)は同時期の増配の効果を除去した後の株式分割の効果を分析している。」と続けている。

<!-- Event studies examine the impact of a class of identifiable events on one or more variables of economic interest.  -->
イベント・スタディは，特定のイベントのクラスが経済的に興味のある1つ以上の変数に与える影響を調査する。
<!-- In capital markets research, the variable of economic interest is typically the returns of a firm’s shares around the event. -->
資本市場研究では，経済的に興味のある変数は，通常，イベントの周辺での企業の株式リターンである。

<!-- The basic ingredients of an event study are: -->
イベント・スタディの基本的な要素は次のとおりである。

<!-- - A class of events: earnings announcements, merger announcements, stock splits, earnings forecast changes. -->
- イベントのクラス：収益発表、合併発表、株式分割、収益予測の変更
<!-- - In many research papers, these events represent the treatment of interest. -->
- 多くの研究論文では，これらのイベントは興味の対象となる処置を表している。
<!-- - An outcome variable of interest: accounting policy, market returns, trading volume. -->
- 興味のある結果変数：会計方針、市場リターン、取引量
<!-- - Control observations: observations for which the event did not occur. -->
- コントロール観測：イベントが発生しなかった観測
<!-- - Control variables: additional variables that may be correlated with both the event—such as dividend announcements with earnings announcements or forecast revisions with earnings announcements—and also returns (see Chapter 4 for more on control variables). -->
- コントロール変数：イベント（たとえば、配当発表と収益発表、予測の修正と収益発表）とリターンの両方と相関する可能性のある追加変数（コントロール変数については、第4章を参照）。

<!-- Additionally, as we saw in Chapter 12, lining up observations in event time is a critical feature of most event studies. -->
さらに，第12章で見たように，観測をイベント時刻に整列させることは，ほとんどのイベント・スタディにおいて重要な特徴である。

<!-- ### 13.1.1 Discussion questions -->
### ディスカッション課題

<!-- Does Ball and Brown (1968) meet the MacKinlay (1997) definition of an event study?  -->
Ball and Brown (1968)はMacKinlay (1997)のイベント・スタディの定義を満たしていますか？
<!-- What features are present and what, if any, are missing? -->
どのような特徴があり，もしあれば何が欠けているか，

<!-- Does Beaver (1968) meet the MacKinlay (1997) definition of an event study?  -->
Beaver (1968)はMacKinlay (1997)のイベント・スタディの定義を満たしていますか？
<!-- What features are present and what, if any, are missing? -->
どのような特徴があり，もしあれば何が欠けているか，


<!-- ## 13.2 The modern event study -->
## 13.2 現代のイベント・スタディ

<!-- The event study has evolved over time.  -->
イベント・スタディは時代とともに進化してきた。
<!-- While event studies today generally meet the definition in MacKinlay (1997), the event-study approach has changed as it has been adapted to a wider variety of situations. -->
現在のイベント・スタディは，一般的にMacKinlay (1997)の定義を満たしているが，様々な状況に適応されるにつれて，イベント・スタディのアプローチは変化してきた。

<!-- One change is that researchers have become more interested in using event studies to understand the economic effects of regulation, rather than the market reaction to firm-specific announcements.  -->
変化の1つは，研究者が，企業固有の発表に対する市場の反応ではなく，規制の経済的影響を理解するためにイベント・スタディを使用することに興味を持つようになったことである。
<!-- Fama et al. (1969) studied stock-splits and Beaver (1968) studied earnings announcements.  -->
Fama et al. (1969)は株式分割を，Beaver (1968)は収益発表を研究した。
<!-- In each case, the events are firm-level events that are largely independent of each other (e.g., they are not excessively clustered in time).  -->
各ケースでは，これらのイベントは，おおむね互いに独立している（たとえば，時間的に過度に集中していない）企業レベルのイベントである。
<!-- In contrast, each of the three more recent event studies we study below uses regulatory events such as events affecting the probability of legislation (Larcker et al., 2011; Zhang, 2007) or accounting standards going into effect (Khan et al., 2017). -->
対照的に，以下で学習する3つの最近のイベント・スタディは，立法の可能性に影響を与えるイベント（Larcker et al., 2011; Zhang, 2007）や会計基準の施行（Khan et al., 2017）などの規制イベントを使用している。

<!-- A related change is an increased reliance on market efficiency, as the typical modern event study uses (in the words of MacKinlay, 1997) “security prices observed over a relatively short time period” as a “measure of the event’s economic impact”.  -->
関連する変化は，市場効率性への依存度の増加であり，典型的な現代のイベント・スタディは，MacKinlay（1997）の言葉で言えば，「比較的短い期間に観察された証券価格」を「イベントの経済的影響の尺度」として使用している。
<!-- Neither Fama et al. (1969) nor Beaver (1968) relies heavily on market efficiency in establishing that markets appear to react to stock-splits and earnings announcements, respectively, and neither study seeks to show whether stock-splits or earnings announcements create (or destroy) value.  -->
Fama et al. (1969)もBeaver (1968)も，株式分割や収益発表に市場が反応するように見えることを確立する際に，市場効率性に大きく依存しておらず，株式分割や収益発表が価値を創出（または破壊）するかどうかを示そうとしていない。
<!-- In contrast, the modern event study is often leaning on market efficiency to evaluate regulation.  -->
対照的に，現代のイベント・スタディは，しばしば規制を評価するために市場効率性に依存している。
<!-- For example, using an event study to ask “do the FASB’s standards add shareholder value?” (Khan et al., 2017) relies heavily on the market having an informed view of the kind implied by stronger forms of market efficiency. -->
たとえば，イベント・スタディを使用して「FASBの基準は株主価値を創出するか？」(Khan et al., 2017)と問うことは，市場がより強度の市場効率性によって暗示されるような情報を持っているという前提に大きく依存している。

<!-- A consequence of this changed emphasis is that often there are fewer independent observations for the researcher to work with. -->
この変化した強調の結果，研究者が取り組む独立した観測が少なくなることがしばしばある。
<!-- For example, the primary analysis of Zhang (2007) focuses on four event windows, far fewer than the 506 earnings announcements in Beaver (1968). -->
たとえば，Zhang (2007)の主要な分析は4つのイベント・ウィンドウに焦点を当てており，Beaver (1968)の506の収益発表よりもはるかに少ない。
<!-- As we will see, researchers often use supplementary analyses to address the relative paucity of data. -->
後述するように，研究者はしばしばデータの相対的な不足を解消するために補助的な分析を行う。



<!-- 13.2.1 A small event study -->
### 小規模なイベント・スタディ

<!-- To better understand the modern event study, we conduct a mini-study of our own.  -->
現代のイベント・スタディをよりよく理解するために，自分自身の小規模な研究を行う。
<!-- Suppose that we want to understand better the value-creation process at Apple with a particular emphasis on Apple’s product development process.  -->
Appleの価値創造プロセスをよりよく理解したいとし，特にAppleの製品開発プロセスに焦点を当てることにしたとしよう。
<!-- At the time of writing (mid-2022), Apple is the most valuable company in the world, with a market capitalization over US$2 trillion; so understanding how it creates value for shareholders may be of interest to researchers. -->
執筆時点（2022年中頃）では，Appleは世界で最も価値のある企業であり，時価総額は2兆ドルを超えている。したがって，株主に価値を創出する方法を理解することは研究者にとって興味深いかもしれない。

<!-- As Apple is notoriously secretive about its product pipeline, the media events at which its products are launched are closely watched affairs.  -->
Appleは製品パイプラインについて非常に秘密主義的であるため，製品が発売されるメディアイベントは注目されることが多い。
<!-- For example, at the Macworld Conference & Expo San Francisco 2007 (9 January 2007), Apple announced the iPhone, which would go on to become Apple’s primary revenue source and one of the largest phone products in the world.  -->
たとえば，2007年1月9日に開催されたMacworld Conference & Expo San Francisco 2007では，AppleはiPhoneを発表し，これがAppleの主要な収益源となり，世界最大の携帯電話製品の1つとなった。
<!-- At an Apple Special Event on 27 January 2010, Apple announced the iPad, Apple’s tablet computer. -->
2010年1月27日に開催されたApple Special Eventでは，AppleはiPadを発表し，Appleのタブレットコンピュータとなった。

<!-- So, to understand whether Apple’s products create value for Apple shareholders, we might run an event study using Apple’s media events as the events of interest. -->
したがって，Appleの製品がAppleの株主に価値を創出するかどうかを理解するために，Appleのメディアイベントを興味の対象としてイベント・スタディを実施することができる。

<!-- The farr package includes the data frame apple_events, which is derived from data found on Wikipedia.  -->
`farr`パッケージには，Wikipediaで見つかったデータを元にしたデータフレーム`apple_events`が含まれています。
<!-- Let’s look at the last few rows of this table: -->
この表の最後の数行を見てみましょう。

```{r}
tail(apple_events)
```

<!-- We will need return data from CRSP to conduct our event study.  -->
イベント・スタディを実施するためには，CRSPからリターンデータが必要となる。
<!-- We first need to get Apple’s PERMNO so we can look up returns on CRSP.  -->
まず，CRSPでリターンを検索できるようにAppleのPERMNOを取得する必要がある。
<!-- Knowing that Apple’s ticker is AAPL helps. -->
AppleのティッカーがAAPLであることを知っていると便利である。

:::{.panel-tabset}

### PostgreSQL

```{r}
#| eval: false
db <- dbConnect(RPostgres::Postgres())

stocknames <- tbl(db, Id(schema = "crsp", table = "stocknames"))
dsf <- tbl(db, Id(schema = "crsp", table = "dsf"))
dsi <- tbl(db, Id(schema = "crsp", table = "dsi"))

idx_daily <- tbl(db, Id(schema = "comp", table = "idx_daily"))
```


### parquet

```{r}
#| eval: false
db <- dbConnect(duckdb::duckdb())

stocknames <- load_parquet(db, schema = "crsp", table = "stocknames")
dsf <- load_parquet(db, schema = "crsp", table = "dsf")
dsi <- load_parquet(db, schema = "crsp", table = "dsi")

idx_daily <- load_parquet(db, schema = "comp", table = "idx_daily")
```

:::



```{r}
#| eval: false

apple_permno <-
  stocknames |> 
  filter(ticker == "AAPL") |> # Apple社
  select(permno) |> # permno変数を選択
  distinct() |> # 重複を削除
  pull() # データを取得
```

<!-- We then use Apple’s PERMNO (apple_permno equals 14593) to get return data from CRSP.  -->
次に，AppleのPERMNO（`apple_permno`は14593）を使用して，CRSPからリターンデータを取得する。
<!-- In this case, we will get daily returns for Apple (ret) from `crsp.dsf` and value-weighted “market” returns (vwretd) from crsp.dsi and calculate market-adjusted returns as `ret - vwretd`.[^2]  -->
この場合，Appleの日次リターン(`ret0`)を`crsp.dsf`から取得し，時価総額加重「市場」リターン(`vwretd`)を`crsp.dsi`から取得し，**市場調整リターン**を`ret - vwretd`として計算する。
<!-- In this case, we will grab all returns since the start of 2005, which covers all the events on apple_events. -->
この場合，2005年初めからのすべてのリターンを取得し，`apple_events`のすべてのイベントをカバーする。


```{r}
#| eval: false

apple_rets <-
  dsf |>
  inner_join(dsi, by = "date") |>
  mutate(ret_mkt = ret - vwretd) |>
  select(permno, date, ret, ret_mkt, vol) |>
  filter(permno == apple_permno,
         date >= "2005-01-01") |>
  collect()
```

<!-- Unlike the earnings announcements that we studied in Chapter 12, Apple’s media events extend over multiple days; so our event windows also need to extend over multiple days.  -->
第12章で学習した利益マネジメントとは異なり，Appleのメディアイベントは複数日にわたって行われるため，イベント・ウィンドウも複数日にわたって拡張する必要がある。
<!-- To allow for some leakage of information in the day before the start of the media events and to allow the market some time to process the value implications of the media event, we will set our event window from one trading day before the start of each media event through to one day after the end of the media event.  -->
情報の漏洩を考慮して，メディアイベントの開始の前日からメディアイベントの終了の翌日までの1取引日をイベント・ウィンドウとして設定し，市場にメディアイベントの価値の意味を処理する時間を与える。
<!-- We will use the get_event_dates() function from the farr package to this end; behind the scenes, get_event_dates() uses get_trading_dates() and get_annc_dates() to get tables like trading_dates and annc_dates, respectively, which we studied in Chapter 12.3 -->
このために，`farr`パッケージの`get_event_dates()`関数を使用する。`get_event_dates()`は，裏で`get_trading_dates()`と`get_annc_dates()`を使用して，第12章で学習した`trading_dates`や`annc_dates`などのテーブルを取得する。


```{r}
#| eval: false

apple_event_dates <-
  apple_events |>
  mutate(permno = apple_permno) |>
  get_event_dates(db,
                  end_event_date = "end_event_date",
                  win_start = -1, win_end = +1)

tail(apple_event_dates)
```

<!-- We now organize the data in a way that allows us to depict Apple’s returns graphically over time including information about media events. -->
Appleのリターンを時系列でグラフィカルに表現するために，メディアイベントに関する情報を含めてデータを整理する。


```{r}
#| eval: false

apple_data <-
  apple_rets |>
  left_join(apple_event_dates,
            join_by(permno, date >= start_date, date <= end_date)) |>
  mutate(is_event = !is.na(start_date)) |>
  select(permno, date, ret, ret_mkt, vol, is_event)
```

<!-- Now we have the data we need, we can calculate cumulative returns using the cumprod() function and then plot these returns over time.[^4] -->
必要なデータが揃ったので，`cumprod()`関数を使用して累積リターンを計算し，これらのリターンを時系列でプロットすることができる。


```{r}
#| eval: false

apple_data |>
  arrange(date) |>
  mutate(cumret = cumprod(1 + coalesce(ret, 0)),
         switch = coalesce(is_event != lead(is_event), FALSE)) |>
  ggplot(aes(x = date, y = cumret)) +
  geom_line() +
  geom_ribbon(aes(ymax = if_else(!is_event | switch, cumret, NA),
                  ymin = 0, fill = "Non-event")) +
  geom_ribbon(aes(ymax = if_else(is_event | switch, cumret, NA),
                  ymin = 0, fill = "Event")) +
  theme(legend.position = "inside", legend.position.inside = c(0.2, 0.8))
```

<!-- The line in Figure 13.1 represents cumulative returns since the start of the window.  -->
図13.1の折れ線は，ウィンドウの開始以来の累積リターンを表している。
<!-- Two “area” plots are added to this line: one for the non-event windows and one for the event windows.  -->
この折れ線には，2つの「エリア」プロットが追加されている：1つは非イベントウィンドウ用，もう1つはイベントウィンドウ用である。
<!-- The vast majority of dates are non-event dates, making the event windows difficult to discern in the plot.  -->
ほとんどの日付は非イベント日であり，プロットではイベントウィンドウを識別するのが難しい。
<!-- But “zooming in” makes the event windows easier to discern, as seen in Figure 13.2, which focuses on the last quarter of 2020. -->
しかし，「ズームイン」することで，イベントウィンドウを識別しやすくなる。図13.2は，2020年第4四半期に焦点を当てている。


```{r}
#| eval: false

apple_data |>  
  arrange(date) |>
  mutate(cumret = cumprod(1 + coalesce(ret, 0)),
         switch = coalesce(is_event != lead(is_event), FALSE)) |>
  filter(date >= "2020-09-01", date <= "2020-12-31") |>
  ggplot(aes(x = date, y = cumret)) +
  geom_line() +
  geom_ribbon(aes(ymax = if_else(!is_event | switch, cumret, NA),
                  ymin = 0, fill = "Non-event")) +
  geom_ribbon(aes(ymax = if_else(is_event | switch, cumret, NA),
                  ymin = 0, fill = "Event")) +
  theme(legend.position = "bottom")
```

<!-- There is little in the plots above to suggest that Apple media events are associated with unusual returns, but we will use regression analysis to test this more formally.  -->
上記のプロットからは，Appleのメディアイベントが異常なリターンと関連していることを示すものはほとんどないが，より形式的にこれをテストするために回帰分析を使用する。
<!-- We consider whether returns are different when the indicator variable is_event is TRUE.  -->
リターンがイベント指標変数がTRUEの場合に異なるかどうかを検討する。
<!-- Inspired by , see 12, we also consider the absolute value of returns (similar to squared return residuals used in Beaver, 1968) and relative trading volume. -->
12章で見たように、Beaver (1968)で使用された二乗リターン残差に類似した絶対リターン値と，相対取引量も考慮する。


```{r}
#| eval: false

fms <- list("ret_mkt" = lm(ret_mkt ~ is_event, data = apple_data),
            "abs(ret)" = lm(abs(ret) ~ is_event, data = apple_data),
            "Volume" = lm(vol / mean(vol) ~ is_event, data = apple_data))
```


```{r}
#| eval: false

fms <- list("ret_mkt" = lm(ret_mkt ~ is_event, data = apple_data),
            "abs(ret)" = lm(abs(ret) ~ is_event, data = apple_data),
            "Volume" = lm(vol / mean(vol) ~ is_event, data = apple_data))
```

<!-- Results from these regressions are reported in Table 13.1. -->
これらの回帰の結果は表13.1に報告されている。
<!-- These results—interpreted fairly casually—provide evidence of lower returns, but not higher (or lower) levels of either trading volume or return volatility. -->
これらの結果は，比較的簡単に解釈すると，低いリターンが示されているが，取引量やリターンのボラティリティの高い（または低い）レベルは示されていない。

<!-- The code above examines whether returns for Apple during event periods behave differently from returns during non-event periods.  -->
上記のコードは，Appleのイベント期間中のリターンが非イベント期間中のリタンと異なるかどうかを調べている。
<!-- Another function from farr, get_event_cum_rets(), calculates cumulative raw returns and cumulative abnormal returns using two approaches: market-adjusted returns and size-adjusted returns over event windows.  -->
`farr`の別の関数である`get_event_cum_rets()`は，2つのアプローチを使用して，イベントウィンドウ全体で市場調整リターンとサイズ調整リターンを使用して，累積生のリターンと累積異常リターンを計算する。
<!-- We use this function to get cumulative returns around each Apple event. -->
この関数を使用して，各Appleイベントの周辺での累積リターンを取得する。


```{r}
#| eval: false

rets <-
  apple_events |>
  mutate(permno = apple_permno) |> 
  get_event_cum_rets(db,
                     win_start = -1, win_end = +1,
                     end_event_date = "end_event_date")
```

<!-- We first look at market-adjusted returns, which on average barely differ from zero. -->
まず，平均的にほとんどゼロと変わらない市場調整リターンを見てみる。


```{r}
#| eval: false

summary(rets$ret_mkt)
```

<!-- How many media events are positive-return events? (Answer: Fewer than half!) -->
正のリターンイベントは何件あるか？（答え：半分以下！）


```{r}
#| eval: false

summary(rets$ret_mkt > 0)
```

<!-- Finally, Figure 13.3 depicts market-adjusted returns for Apple media events by event date. -->
最後に，図13.3は，イベント日によるAppleメディアイベントの市場調整リターンを描いている。


```{r}
#| eval: false

rets |>
  ggplot(aes(x = event_date, y = ret_mkt)) +
  geom_point() +
  geom_smooth(method = "lm", formula = "y ~ 1")
```

<!-- ### 13.2.2 Exercises -->
### 演習

<!-- How would you expect the plot to change if we used `cumret = exp(cumsum(log(1 + coalesce(ret, 0))))` in place of `cumret = cumprod(1 + coalesce(ret, 0))` in creating the plot above?  -->
上記のプロット作成時に，`cumret = cumprod(1 + coalesce(ret, 0))`の代わりに`cumret = exp(cumsum(log(1 + coalesce(ret, 0))))`を使用した場合，プロットがどのように変化すると予想されるか。
<!-- Is there any reason to prefer one calculation over time other? -->
時間の経過とともに1つの計算を他の計算よりも好む理由はありますか。

<!-- Do we get different results in this case if we use `cumret = cumprod(1 + ret)` (i.e., remove the coalesce() function)?  -->
この場合，`cumret = cumprod(1 + ret)`（つまり，`coalesce()`関数を削除）を使用した場合，異なる結果が得られますか？
<!-- If so, why?  -->
もしそうならば，なぜか？
<!-- If not, would we always expect this to be case (e.g., for stocks other than Apple)? -->
そうでない場合，常にこのようなケースであることを期待する理由はあるか（たとえば，Apple以外の株式の場合）？

<!-- 13.3 Event studies and regulation -->
## 13.3 イベント・スタディと規制

<!-- Zhang (2007, p. 74) “investigates the economic consequences of the Sarbanes–Oxley Act (SOX) by examining market reactions to related legislative events.”  -->
Zhang (2007, p. 74)は，「関連する立法イベントに対する市場の反応を調査することで，サーバンズ・オクスリー法（SOX）の経済的影響を調査する」と述べている。
<!-- Zhang (2007, p. 75) finds that “the cumulative value-weighted (equal-weighted) raw return of the U.S. market amounts to –15.35% (–12.53%) around the key SOX events.”  -->
Zhang (2007, p. 75)は，「米国市場の累積時価加重（等時価加重）生のリターンは，主要なSOXイベントの周辺でそれぞれ-15.35%（-12.53%）に相当する」と結論付けている。
<!-- As Zhang (2007) uses CRSP returns for the US market, we collect a local copy of the relevant data. -->
Zhang (2007)は米国市場のCRSPリターンを使用しているため，関連データのローカルコピーを収集する。


```{r}
#| eval: false

dsi_local <-
  dsi |>
  select(date, vwretd, ewretd) |>
  collect()
```

<!-- Zhang (2007, p. 76) focuses some analyses on “key SOX events” (defined below) and finds that “the estimated U.S. cumulative abnormal returns range from –3.76% and –8.21% under alternative specifications and are all statistically significant.”  -->
Zhang (2007, p. 76)は，「主要なSOXイベント」（以下で定義）に焦点を当てたいくつかの分析を行い，「代替仕様において推定された米国の累積異常リターンは，すべて統計的に有意であり，-3.76%から-8.21%の範囲に及ぶ」と結論付けている。
<!-- Here “all” means for each of value-weighted and equal-weighted returns and using abnormal returns relative to each of the two models.  -->
ここでの「すべて」とは，時価加重リターンと等時価加重リターンのそれぞれについて，および2つのモデルに対する異常リターンを使用していることを意味する。
<!-- For convenience, we focus on the model that measures abnormal returns relative to a “market model”, where the market comprises Canadian stocks not listed in the United States, and omit analysis of the second model, which blends returns on several non-US portfolios as a benchmark.  -->
便宜上，米国に上場していないカナダの株式からなる市場を対象とした「市場モデル」に対する異常リターンを測定するモデルに焦点を当て，複数の非米国ポートフォリオのリターンを基準としてブレンドする第2のモデルの分析を省略する。
<!-- To this end, we collect data on returns for the Toronto composite index (gvkeyx == "000193") from Compustat’s index data (comp.idx_daily) over 2001 and 2002 and merge this data set with our local copy of crsp.dsi. -->
このために，2001年と2002年のCompustatの指数データ（`comp.idx_daily`）からトロント総合指数（`gvkeyx == "000193"`）のリターンデータを収集し，このデータセットをローカルコピーの`crsp.dsi`とマージする。


```{r}
#| eval: false

can_rets <-
  idx_daily |> 
  filter(gvkeyx == "000193") |> 
  window_order(datadate) |>
  mutate(ret_can = if_else(lag(prccd) > 0, prccd/lag(prccd) - 1, NA)) |> 
  filter(datadate >= "2000-01-01", datadate <= "2002-12-31") |>
  rename(date = datadate) |>
  select(date, ret_can) |>
  collect()
```

<!-- We follow Zhang (2007, p. 88) in “using daily return data in the 100 days prior to December 28, 2001” for expected return models. -->
Zhang (2007, p. 88)に従い，予想リターンモデルには「2001年12月28日の100日前の日次リターンデータ」を使用する。


```{r}
#| eval: false

reg_data <-
  dsi_local |>
  inner_join(can_rets, by = "date") |>
  filter(date < "2001-12-28") |>
  top_n(100, wt = date) 
```

<!-- We then fit models for market returns for both equal-weighted and value-weighted portfolios against Canadian returns. -->
次に，等時価加重ポートフォリオと時価加重ポートフォリオの市場リターンモデルをカナダのリターンに対して適合させる。


```{r}
#| eval: false

fm_vw <- lm(vwretd ~ ret_can, data = reg_data)
fm_ew <- lm(ewretd ~ ret_can, data = reg_data)
```

<!-- We then use these models to calculate excess returns for all observations.  -->
つぎに、これらのモデルを使用してすべての観測値の超過リターンを計算する。
<!-- In the following code, we use pick(everything()), which is an idiom that we use in a few places in this book.  -->
以下のコードでは、この本のいくつかの場所で使用するイディオムである`pick(everything())`を使用している。
<!-- In the function following the native pipe (|>), we often access the data frame supplied by the item preceding |> using the pipe placeholder _.  -->
ネイティブパイプ（`|>`）に続く関数では、しばしばパイププレースホルダ`_`を使用して、パイプの前に供給されたデータフレームにアクセスする。
<!-- However, this placeholder is not accessible to functions inside mutate().  -->
ただし、このプレースホルダは、`mutate()`内の関数からはアクセスできません。
<!-- Fortunately, we can use pick() instead.  -->
幸いなことに、代わりに`pick()`を使用できる。
<!-- The pick() function provides a way to easily select columns from data inside a function like mutate().  -->
`pick()`関数は、`mutate()`のような関数内でデータから列を簡単に選択する方法を提供する。
<!-- In the current setting, we can use everything() to indicate that we want to select all variables in the source data.  -->
現在の設定では、`everything()`を使用して、ソースデータのすべての変数を選択することを示すことができる。
<!-- As such, pick(everything()) is a handy workaround to the limitations of the pipe placeholder _. -->
そのため、`pick(everything())`は、パイププレースホルダ`_`の制限を回避するための便利な回避策である。


```{r}
#| eval: false

dsi_merged <-
  dsi_local |>
  inner_join(can_rets, by = "date") |>
  mutate(abret_vw = vwretd - predict(fm_vw, pick(everything())),
         abret_ew = ewretd - predict(fm_ew, pick(everything()))) |>
  select(-ret_can)
```

<!-- From Table 2, Zhang (2007) appears to calculate the daily standard deviation of returns at about 1.2%.  -->
表2から、Zhang (2007)はリターンの日次標準偏差を約1.2%として計算しているようだ。
<!-- The exact basis for this calculation is unclear, but similar analyses are “estimated using daily return data in the 100 days prior to December 28, 2001” (Zhang, 2007, p.88).  -->
この計算の正確な根拠は不明だが，類似した分析は「2001年12月28日の100日前の日次リターンデータを使用して推定される」(Zhang, 2007, p.88). 
<!-- So we calculate the daily volatility on this basis using the following calculation, which yields the value 1.28%. -->
したがって，以下の計算を使用してこの基準で日次ボラティリティを計算し，1.28%という値を得る。


```{r}
#| eval: false

sd_ret <-
  dsi_local |>
  filter(date < "2001-12-28") |>
  top_n(100, wt = date) |>
  summarize(sd(vwretd)) |>
  pull()
```

<!-- The `farr` package contains the data frame zhang_2007_windows containing the dates of the event windows found in Table 2 of Zhang (2007).  -->
`farr`パッケージには，Zhang (2007)の表2にあるイベント・ウィンドウの日付が含まれているデータフレーム`zhang_2007_windows`が含まれている。
<!-- We can combine these data with return data from dsi_local to calculate cumulative returns for each event window.  -->
これらのデータを`dsi_local`からのリターンデータと組み合わせて，各イベント・ウィンドウの累積リターンを計算することができる。
<!-- Following Zhang (2007), we can estimate the standard error by scaling the daily return volatility by the square-root of the number of trading days in each window to calculate a t-statistic for each event.  -->
Zhang (2007)に従い，各イベントについてt統計量を計算するために，各ウィンドウの取引日数の平方根で日次リターンのボラティリティをスケーリングして標準誤差を推定することができる。
<!-- We use the standard deviation of residuals to estimate the daily volatility of the abnormal-return models. -->
異常リターンモデルの日次ボラティリティを推定するために，残差の標準偏差を使用する。


```{r}
#| eval: false

zhang_2007_rets <-
  zhang_2007_windows |>
  inner_join(dsi_merged, join_by(beg_date <= date, end_date >= date)) |>
  group_by(event) |>
  summarize(n_days = n(),
            vwret = sum(vwretd),
            ewret = sum(ewretd),
            abret_vw = sum(abret_vw),
            abret_ew = sum(abret_ew),
            vw_t = vwret / (sqrt(n_days) * sd_ret),
            ew_t = ewret / (sqrt(n_days) * sd_ret),
            abret_vw_t = abret_vw / (sqrt(n_days) * sd(fm_vw$residuals)),
            abret_ew_t = abret_ew / (sqrt(n_days) * sd(fm_ew$residuals)))
```

<!-- In subsequent analyses, Zhang (2007) focuses on “key SOX events”, which seem to be those events with a “statistically significant” return at the 10% level in a two-tailed test, and reports results in Panel D of Table 1 (2007, pp. 91–92). -->
その後の分析では，Zhang (2007)は「主要なSOXイベント」に焦点を当てているようであり，これらのイベントは「統計的に有意な」リターンを持つイベントのようであり，表1のパネルD（2007年，91-92ページ）に結果を報告している。
<!-- We replicate the key elements of this procedure and our results correspond roughly with those reported in Zhang (2007) as “CAR2”. -->
この手順の主要な要素を再現し，我々の結果はZhang (2007)で「CAR2」として報告された結果とおおよそ一致している。


```{r}
#| eval: false

zhang_2007_res <-
  zhang_2007_rets |>
  filter(abs(vw_t) > abs(qnorm(.05))) |>
  summarize(vwret = sum(vwret),
            ewret = sum(ewret),
            abret_vw = sum(abret_vw),
            abret_ew = sum(abret_ew),
            n_days = sum(n_days),
            vw_t = vwret / (sqrt(n_days) * sd_ret),
            ew_t = ewret / (sqrt(n_days) * sd_ret),
            abret_vw_t = abret_vw / (sqrt(n_days) * sd(fm_vw$residuals)),
            abret_ew_t = abret_ew / (sqrt(n_days) * sd(fm_ew$residuals)))
```

<!-- We estimate cumulative raw value-weighted returns for the four “key SOX events” at  $-15.2\%$ (t-statistic $-3.18$ ), quite close to the value reported in Zhang (2007) ( $-15.35\%$ with a $t$ -statistic of $-3.49$ ).  -->
「主要なSOXイベント」における累積生の時価加重リターンを推定すると、 $-15.2\%$ （$t $統計量 $-3.18$ ）となり、Zhang (2007)で報告された値 $-15.35\%$ （ $t$ 統計量 $-3.49$ ）に非常に近い。
<!-- However, our estimate of cumulative abnormal value-weighted returns for the four “key SOX events” is $-3.18\%$ ($t$ -statistic $-1.02$ ), which is closer to zero than the value reported in Zhang (2007) ( $-8.21\%$ with a $t$ -statistic of $-2.99$ ), which is the only value of eight reported in Panel D of Table 1 that is statistically significant at conventional levels (5% in two-tailed tests). -->
しかし、4つの「主要なSOXイベント」における累積異常時価加重リターンの推定値は $-3.18\%$ （$t$ 統計量 $-1.02$ ）であり、Zhang (2007)で報告された値 $-8.21\%$ （$t$ 統計量 $-2.99$ ）よりもゼロに近い。これは、表1のパネルDで報告された8つの値のうち、従来のレベル（両側検定で5%）で統計的に有意な唯一の値である。

<!-- 13.3.1 Discussion questions -->
### 13.3.1 ディスカッション課題

<!-- ####  13.3.1.1 Zhang (2007)  -->
#### Zhang (2007)

<!-- What are the relative merits of raw and abnormal returns in evaluating the effect of SOX on market values of US firms? -->
1. 米国企業の市場価値に対するSOXの影響を評価する際に，生のリターンと異常リターンの相対的なメリットは何か？
<!-- What do you observe in the raw returns for Canada, Europe, and Asia for the four events that are the focus of Panel B of Table 2 of Zhang (2007)?  -->
Zhang (2007)の表2のパネルBの焦点となる4つのイベントについて，カナダ，ヨーロッパ，アジアの生のリターンについて何が観察されるか？
<!-- Does this raise concerns about the results of Zhang (2007)? -->
これは，Zhang (2007)の結果について懸念を抱かせるか？

<!-- Describe the process for constructing the test statistics reported in Panel D of Table 2.  -->
2. 表2のパネルDに報告されている検定統計量を構築するプロセスを説明せよ。
<!-- How compelling are these results? Do you agree with the assessment by Leuz (2007, p. 150) that Zhang (2007) is “very careful in assessing the significance of the event returns”? -->
これらの結果はどれほど説得力があるか？Leuz (2007, p. 150)によると，Zhang (2007)は「イベントリターンの有意性を評価する際に非常に慎重である」と評価しているが，これに同意するか？

<!-- Describe in detail how you might conduct statistical inference using randomization inference in the setting of Zhang (2007) (see Section 19.7 for more on this approach)? -->
3. Zhang (2007)の設定でランダム化推論を使用して統計推論をどのように実施するかを詳細に説明せよ（このアプローチについては，19.7節を参照）。
<!-- What are the challenges faced and design choices you need to make in applying this approach? Does your approach differ from the bootstrapping approach used in Zhang (2007)? -->
このアプローチを適用する際に直面する課題と設計上の選択肢は何か？このアプローチは，Zhang (2007)で使用されているブートストラップアプローチと異なるか？

<!-- Leuz (2007) identifies studies other than Zhang (2007) that find evidence that SOX was beneficial to firms?  -->
4. Leuz (2007)は，SOXが企業にとって有益であるという証拠を見つけたZhang (2007)以外の研究を特定しているか？
<!-- How can these sets of results be reconciled?  -->
これらの結果をどのように調整できるか？
<!-- What steps would you look to undertake to evaluate the conflicting claims of the two papers? -->
2つの論文の相反する主張を評価するために，どのような手順を踏むか？

<!-- #### 13.3.1.2 Khan et al. (2017)  -->
#### Khan et al. (2017)

<!-- What is the research question examined in Khan et al. (2017)?  -->
1. Khan et al. (2017)で検討されている研究課題は何か？
<!-- (Hint: Read the title.) -->
（ヒント：タイトルを読んでください。）

<!-- Khan et al. (2017, p. 210) argue that “an ideal research design to evaluate the benefits of accounting standards is to compare a voluntary disclosure regime, in which firms disclose information required by a particular standard, with a mandatory disclosure regime, in which firms are required to disclose that same information.”  -->
2. Khan et al. (2017, p. 210)は「会計基準の利点を評価するための理想的な研究デザインは，企業が特定の基準によって要求される情報を開示する任意の開示体制と，企業が同じ情報を開示することが義務付けられる強制的な開示体制を比較することである」と主張している。
<!-- Do you agree that this research design would be “ideal” to address the question?  -->
この研究デザインがこの問題に対処するために「理想的」であると思うか？
<!-- What is the implied treatment in this ideal design? -->
この理想的なデザインで暗示される処置は何か？

<!-- Compare the Apple event study above with Khan et al. (2017). What are the relative strengths and weaknesses of the two studies?  -->
3. 上記のAppleイベントスタディとKhan et al. (2017)を比較して，2つの研究の相対的な強みと弱みは何か？
<!-- Do you think an event-study approach is appropriate for addressing the question “do Apple products add value?”  -->
「Apple製品は価値を追加するか？」という問題に対処するために，イベントスタディアプローチは適切だと考えるか？
<!-- Do you think an event-study approach is appropriate for addressing the research question of Khan et al. (2017)?  -->
Khan et al. (2017)の研究問題に対処するために，イベントスタディアプローチは適切だと考えるか？
<!-- Why or why not? -->
その理由は何か？

<!-- Do you think that standard-setters would view “reduction in estimation risk” as a goal of accounting standards?  -->
4. 会計基準制定者は，「推定リスクの低減」を会計基準の目標と見なすと思うか？
<!-- Evaluate the quality of the arguments linking improved standards to reduced estimation risk.  -->
改善された基準と推定リスクの低減を結びつける議論の質を評価せよ。
<!-- The null hypothesis for Panel A is that the CAR of affected firms is not different from CAR of unaffected firms.  -->
Panel Aの帰無仮説は，影響を受けた企業のCARが影響を受けていない企業のCARと異ならないというものである。
<!-- How appropriate is it to report “most negative” and “most positive” CAR differences only?  -->
「最も負の」CAR差と「最も正の」CAR差のみを報告することは適切か？
<!-- (Hint: If the null hypothesis is true, how many standards might you expect to have “statistically significant” coefficients?) -->
（ヒント：帰無仮説が真である場合，「統計的に有意な」係数を持つ基準は何個あると予想できるか？）

<!-- Interpret the results of Table 5, Panel B of Khan et al. (2017). -->
5. Khan et al. (2017)の表5のパネルBの結果を解釈せよ。

<!-- #### 13.3.1.3 Larcker et al. (2011) “LOT” -->
#### Larcker et al. (2011) “LOT”


<!-- 1. How do LOT and FFJR differ in terms of the role of market efficiency in their research designs? -->
1. LOTとFFJRは，研究デザインにおける市場効率の役割についてどのように異なるか？

<!-- 2. Consider Table 1 of LOT. What are the differences between the event study design in LOT from that in FFJR?  -->
2. LOTの表1を考えてみよ。LOTのイベントスタディデザインとFFJRのデザインの違いは何か？
<!-- What are implications of these differences? -->
これらの違いの意味は何か？

<!-- 3. How do you think Table 1 was developed?  -->
3. Table 1はどのように作成されたと考えるか？
<!-- Do you see potential problems in the process underlying Table 1?  -->
Table 1の基礎となるプロセスに潜在的な問題があると思うか？
<!-- Can you suggest alternative approaches to developing Table 1? -->
Table 1を作成するための代替アプローチを提案できるか？

<!-- 4. Consider proxy access, as some of the core results of the paper relate to proxy access.  -->
4. プロキシアクセスを考えてみよ，論文の中心的な結果のいくつかはプロキシアクセスに関連している。
<!-- If you were a shareholder in a company, what concerns might you have about proxy access?  -->
もし会社の株主であるとしたら，プロキシアクセスについてどのような懸念があるか？
<!-- Why might this decrease the value of your shares?  -->
なぜこれがあなたの株式の価値を減少させる可能性があるか？
<!-- Think about this is concrete terms; be specific about the kinds of circumstances where value will be reduced. -->
具体的な事例について考えてみよ；価値が低下する状況について具体的に述べよ。
<!-- How well do the variables NLargeBlock and NSmallCoalitions measure the exposure of firms to the issues you identified in the previous question?  -->
前の質問で特定した問題に企業がどのようにさらされているかを測定するために，変数NLargeBlockとNSmallCoalitionsはどの程度適しているか？
<!-- (As part of this, consider the timing of variable measurement relative to the timing of possible value-reducing outcomes.) -->
（これに関連して，可能な価値低下の結果のタイミングと変数測定のタイミングを考慮してください。）

<!-- 5. LOT makes use of a number of **Monte Carlo simulations**. How do these compare with the bootstrapping analyses conducted by Zhang (2007)?  -->
5. LOTはいくつかの**モンテカルロシミュレーション**を使用している。これらは，Zhang (2007)によるブートストラップ解析とどのように比較されるか？
<!-- Are the simulations addressing the same underlying issues as Zhang (2007) bootstrapping approach? -->
シミュレーションは，Zhang (2007)のブートストラップアプローチと同じ基本的な問題に対処しているか？

